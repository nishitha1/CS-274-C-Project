{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "multi-label-classification-bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NvJS79Am2Pm"
      },
      "source": [
        "# BERT for Multi-Label Classification\n",
        "Refer post : https://medium.com/@javaid.nabi/building-a-multi-label-text-classifier-using-bert-and-tensorflow-f188e0ecdc5d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCLrYM9ZvT3X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65c510b4-f13b-498e-d627-b6907bb3f30c"
      },
      "source": [
        "cd /content/drive/My Drive/Pre-processed-Stack-exchange"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Pre-processed-Stack-exchange\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTi62dqdvZGS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "532757b5-3855-4b99-b638-c82f9a7e8d7d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK63D-9g_lCa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "76f872fc-92c5-44e5-ae2c-6737f2cfce8b"
      },
      "source": [
        "#!unzip 'uncased_L-12_H-768_A-12 (2)'.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  uncased_L-12_H-768_A-12 (2).zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L_5QMvnm2Pp"
      },
      "source": [
        "import os\n",
        "import collections\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofJSB75HuFHK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "7914edec-6880-4e1a-d7a9-66fd8fe8d761"
      },
      "source": [
        "#!pip uninstall tensorflow==2.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.2.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.2.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmtk9cDAuF37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "outputId": "5b7c32ef-c08f-412b-8d4b-cde111c37bd5"
      },
      "source": [
        "#!pip install tensorflow==1.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 30kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 42.2MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.29.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.2.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (47.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=a73c275a9c8a82aa80235d0dda896a95ae96a03732f46ceb649beb0472ecc90e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, gast, tensorflow\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F4Hzeanm2P1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "edc00d19-b5d9-46c3-af7b-20e5ec5e3efe"
      },
      "source": [
        "##install bert if not already done\n",
        "!pip install bert-tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dequnuZDm2P-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "916a970b-40ac-4f3c-8bbb-8df737e9a96e"
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization\n",
        "from bert import modeling"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anMkXXA4m2QC"
      },
      "source": [
        "##use downloaded model, change path accordingly\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "#'/content/drive/My Drive/DecompRC-master/DecompRC/model/uncased_L-12_H-768_A-12'\n",
        "BERT_VOCAB= '/content/drive/My Drive/Pre-processed-Stack-exchange/uncased_L-12_H-768_A-12/vocab.txt'\n",
        "#'./uncased_L-12_H-768_A-12/vocab.txt'\n",
        "\n",
        "#'./uncased_L-12_H-768_A-12/vocab.txt'\n",
        "BERT_INIT_CHKPNT = '/content/drive/My Drive/Pre-processed-Stack-exchange/uncased_L-12_H-768_A-12/bert_model.ckpt'\n",
        "BERT_CONFIG = '/content/drive/My Drive/Pre-processed-Stack-exchange/uncased_L-12_H-768_A-12/bert_config.json'\n",
        "#'./uncased_L-12_H-768_A-12/bert_config.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSGe_yKtm2QH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "621bd447-acd7-4582-c4f9-7769d8597d4c"
      },
      "source": [
        "# tokenization.validate_case_matches_checkpoint(True,BERT_INIT_CHKPNT)\n",
        "# tokenizer = tokenization.FullTokenizer(\n",
        "#       vocab_file=BERT_VOCAB, do_lower_case=True)\n",
        "\n",
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jpBcgtxm2QM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "7f7cdc0e-1dcc-4923-c956-c4bbb699dc75"
      },
      "source": [
        "tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'here',\n",
              " \"'\",\n",
              " 's',\n",
              " 'an',\n",
              " 'example',\n",
              " 'of',\n",
              " 'using',\n",
              " 'the',\n",
              " 'bert',\n",
              " 'token',\n",
              " '##izer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biq9r9Eam2QR"
      },
      "source": [
        "##change path accordingly\n",
        "#train_data_path='./Downloads/train.csv'\n",
        "#train = pd.read_csv(train_data_path)\n",
        "train = pd.read_csv('Pre_No_dup_Chunk1.csv', encoding = 'utf-8', lineterminator='\\n') #change name here \n",
        "#test = pd.read_csv('./Downloads/test.csv')\n",
        "test = pd.read_csv('ShuffleDataChunk010.csv', encoding = 'utf-8', lineterminator='\\n') #change name here \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz-wqN8fm2Qb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "10a5d010-57b0-46fc-e197-019fb2fec91f"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000002</td>\n",
              "      <td>forcin nginx to render uri from rails using pa...</td>\n",
              "      <td>is it possible to force nginx to render some u...</td>\n",
              "      <td>nginx subdomain ruby-on-rails phusion-passenger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000003</td>\n",
              "      <td>forcing   0000  timezone for rfc2822 times in ...</td>\n",
              "      <td>how can i force the time rfc2822 function to s...</td>\n",
              "      <td>ruby time formatting rfc822 rfc2822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000004</td>\n",
              "      <td>forcing  windows xp  style on a c  form based ...</td>\n",
              "      <td>i have written an application using visual stu...</td>\n",
              "      <td>c# visual-studio-2008 themes styles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000005</td>\n",
              "      <td>forcing  auto rotate     auto portrait landsca...</td>\n",
              "      <td>i have been poking around the javascript api f...</td>\n",
              "      <td>javascript pdf adobe pdf-generation adobe-reader</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000006</td>\n",
              "      <td>forcing  date  to use a locale other than the ...</td>\n",
              "      <td>is there a way to force the  nix command  date...</td>\n",
              "      <td>bash unix date</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id  ...                                              Tags\n",
              "0  1000002  ...   nginx subdomain ruby-on-rails phusion-passenger\n",
              "1  1000003  ...               ruby time formatting rfc822 rfc2822\n",
              "2  1000004  ...               c# visual-studio-2008 themes styles\n",
              "3  1000005  ...  javascript pdf adobe pdf-generation adobe-reader\n",
              "4  1000006  ...                                    bash unix date\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDSxV9VInAsc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "7c0d62b0-b8ec-4701-88be-96aaa37523bd"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4142442</td>\n",
              "      <td>unable to iterate over an array in hash in per...</td>\n",
              "      <td>please help me resolve this issue pre_package_...</td>\n",
              "      <td>perl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>773684</td>\n",
              "      <td>do rdlcs require anything different from the b...</td>\n",
              "      <td>so i am new to microsofts reporting system  an...</td>\n",
              "      <td>reporting-services ssrs-reports</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>216907</td>\n",
              "      <td>app on facebook mobile gives me 4oh4   404</td>\n",
              "      <td>we have created a facebook app  but when openi...</td>\n",
              "      <td>facebook application mobile http-status-code-404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2908899</td>\n",
              "      <td>smart device framework highlights</td>\n",
              "      <td>i am thinking about introducing opennetcf is s...</td>\n",
              "      <td>.net compact-framework smart-device-framework</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1059195</td>\n",
              "      <td>getting  subquery returned more than 1 value e...</td>\n",
              "      <td>if i doselect   from cte1 c    where c grantnu...</td>\n",
              "      <td>sql-server sql-server-2008</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id  ...                                              Tags\n",
              "0  4142442  ...                                              perl\n",
              "1   773684  ...                   reporting-services ssrs-reports\n",
              "2   216907  ...  facebook application mobile http-status-code-404\n",
              "3  2908899  ...     .net compact-framework smart-device-framework\n",
              "4  1059195  ...                        sql-server sql-server-2008\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngAp4ccCnh2m"
      },
      "source": [
        "train = train.sample(5000)\n",
        "test = test.sample(5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFIEKYKnlgP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8768562-c8a1-48f2-aabb-9cbc3f2f069e"
      },
      "source": [
        "train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Id', 'Title', 'Body', 'Tags'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2Rz4MOrnmJX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15a43994-4857-4d5e-cbda-b943e3d5e117"
      },
      "source": [
        "test.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Id', 'Title', 'Body', 'Tags'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5fAiDa9oJNX"
      },
      "source": [
        "#Making a dictionary of word tags #TRAIN\n",
        "train.Tags = train.Tags.apply(lambda x: str(x).split())\n",
        "train_tag_freq_dict = {}\n",
        "for tags in train.Tags:\n",
        "    for tag in tags:\n",
        "        if tag not in train_tag_freq_dict:\n",
        "            train_tag_freq_dict[tag] = 0\n",
        "        else:\n",
        "            train_tag_freq_dict[tag] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrAnl1sYoJMH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "984a42a2-8ac9-4446-c734-313584429714"
      },
      "source": [
        "# Get most common tags\n",
        "tags_to_use = 50 #was 200\n",
        "train_tag_freq_dict_sorted = dict(sorted(train_tag_freq_dict.items(), key=lambda x: x[1], reverse=True))\n",
        "train_final_tags = list(train_tag_freq_dict_sorted.keys())[:tags_to_use]\n",
        "len(train_final_tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE92zb41oJKh"
      },
      "source": [
        "# Change tag data to only for final_tags\n",
        "train_final_tag_data = []\n",
        "for tags in train.Tags:\n",
        "    temp = []\n",
        "    for tag in tags:\n",
        "        if tag in train_final_tags:\n",
        "            temp.append(tag)\n",
        "    train_final_tag_data.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzc2z7fEoJF7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e5aa6949-0d8f-4a49-f06b-970323c823e8"
      },
      "source": [
        "train_final_tag_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['objective-c'],\n",
              " [],\n",
              " [],\n",
              " ['c#'],\n",
              " ['c#', 'android'],\n",
              " [],\n",
              " ['linux', 'bash'],\n",
              " [],\n",
              " [],\n",
              " ['java'],\n",
              " ['java', 'html'],\n",
              " ['c++'],\n",
              " ['windows'],\n",
              " [],\n",
              " [],\n",
              " ['asp.net'],\n",
              " [],\n",
              " [],\n",
              " ['android'],\n",
              " ['python'],\n",
              " [],\n",
              " ['python'],\n",
              " [],\n",
              " ['vb.net'],\n",
              " [],\n",
              " ['objective-c'],\n",
              " [],\n",
              " ['linux'],\n",
              " ['php', 'javascript'],\n",
              " ['web-services'],\n",
              " ['java'],\n",
              " ['c'],\n",
              " [],\n",
              " [],\n",
              " ['eclipse'],\n",
              " ['c#'],\n",
              " ['c#', '.net', 'asp.net'],\n",
              " ['jquery'],\n",
              " ['android'],\n",
              " [],\n",
              " [],\n",
              " ['python'],\n",
              " ['c#'],\n",
              " ['linux'],\n",
              " [],\n",
              " ['javascript', 'arrays'],\n",
              " ['mysql', 'sql-server'],\n",
              " [],\n",
              " [],\n",
              " ['c++'],\n",
              " ['android'],\n",
              " [],\n",
              " ['c++'],\n",
              " ['c#'],\n",
              " [],\n",
              " ['windows-7'],\n",
              " ['sql-server'],\n",
              " ['linux', 'bash'],\n",
              " ['php', 'css'],\n",
              " ['android'],\n",
              " ['jquery'],\n",
              " ['php', 'html'],\n",
              " ['javascript'],\n",
              " ['c++'],\n",
              " ['android'],\n",
              " ['git'],\n",
              " ['ruby-on-rails'],\n",
              " ['vb.net'],\n",
              " ['java'],\n",
              " [],\n",
              " ['c#', 'wpf', 'winforms'],\n",
              " [],\n",
              " [],\n",
              " ['python'],\n",
              " ['java', 'database'],\n",
              " ['php'],\n",
              " ['android'],\n",
              " ['python'],\n",
              " ['javascript', 'jquery'],\n",
              " ['linux'],\n",
              " ['mysql'],\n",
              " ['jquery', 'css'],\n",
              " ['c#', 'wpf'],\n",
              " [],\n",
              " ['java', 'forms'],\n",
              " ['iphone', 'ios'],\n",
              " ['c#', 'asp.net'],\n",
              " ['linux'],\n",
              " [],\n",
              " [],\n",
              " ['php', 'mysql'],\n",
              " ['c#'],\n",
              " [],\n",
              " ['.net', 'winforms'],\n",
              " [],\n",
              " [],\n",
              " ['c#', '.net'],\n",
              " ['ruby-on-rails', 'ruby', 'ruby-on-rails-3'],\n",
              " ['c#', '.net', 'winforms'],\n",
              " ['java'],\n",
              " ['html', 'css'],\n",
              " ['java'],\n",
              " [],\n",
              " ['java'],\n",
              " ['android'],\n",
              " [],\n",
              " [],\n",
              " ['java', 'javascript'],\n",
              " [],\n",
              " ['android'],\n",
              " ['ios'],\n",
              " ['android'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['php'],\n",
              " ['linux', 'ubuntu'],\n",
              " [],\n",
              " ['.net', 'asp.net'],\n",
              " ['java'],\n",
              " [],\n",
              " ['c#'],\n",
              " ['javascript', 'jquery', 'html'],\n",
              " ['php'],\n",
              " ['asp.net'],\n",
              " [],\n",
              " ['objective-c'],\n",
              " ['java'],\n",
              " ['xml'],\n",
              " ['javascript', 'jquery'],\n",
              " [],\n",
              " ['c#', 'javascript', 'asp.net', 'asp.net-mvc'],\n",
              " ['windows'],\n",
              " ['javascript', 'jquery', 'ajax'],\n",
              " ['sql', 'database'],\n",
              " ['xml'],\n",
              " [],\n",
              " [],\n",
              " ['sql'],\n",
              " ['sql'],\n",
              " [],\n",
              " ['python', 'xml'],\n",
              " ['c#', '.net'],\n",
              " [],\n",
              " ['iphone'],\n",
              " ['java', 'web-services', 'eclipse'],\n",
              " ['html'],\n",
              " ['java'],\n",
              " [],\n",
              " ['ios'],\n",
              " ['html', 'css'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['html', 'css'],\n",
              " ['c#', 'sql'],\n",
              " ['java', 'javascript'],\n",
              " ['c'],\n",
              " [],\n",
              " ['c++'],\n",
              " ['php', 'mysql'],\n",
              " [],\n",
              " ['linux'],\n",
              " ['windows-7'],\n",
              " [],\n",
              " [],\n",
              " ['.net'],\n",
              " ['php'],\n",
              " ['javascript'],\n",
              " ['java'],\n",
              " ['c#', '.net', 'winforms'],\n",
              " [],\n",
              " [],\n",
              " ['python'],\n",
              " ['c#', 'c++'],\n",
              " ['.net'],\n",
              " ['linux'],\n",
              " [],\n",
              " ['css'],\n",
              " ['git'],\n",
              " ['jquery', 'asp.net'],\n",
              " [],\n",
              " ['asp.net', 'javascript', 'jquery'],\n",
              " ['c#', 'asp.net'],\n",
              " ['iphone', 'objective-c'],\n",
              " ['sql'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['jquery'],\n",
              " ['c++', 'arrays', 'algorithm'],\n",
              " [],\n",
              " [],\n",
              " ['c#'],\n",
              " [],\n",
              " ['c#'],\n",
              " [],\n",
              " ['c#', 'winforms'],\n",
              " ['windows'],\n",
              " ['android'],\n",
              " ['sql'],\n",
              " ['c#', 'asp.net'],\n",
              " [],\n",
              " ['javascript', 'python'],\n",
              " ['jquery'],\n",
              " [],\n",
              " ['javascript', 'html'],\n",
              " [],\n",
              " ['jquery'],\n",
              " ['java'],\n",
              " ['python', 'html'],\n",
              " ['mysql', 'php'],\n",
              " [],\n",
              " ['java', 'android'],\n",
              " ['django'],\n",
              " ['html', 'css', 'html5'],\n",
              " ['javascript', 'arrays'],\n",
              " ['linux'],\n",
              " ['python', 'django'],\n",
              " ['c#', 'sql'],\n",
              " [],\n",
              " ['c#', 'sql', 'sql-server'],\n",
              " ['html', 'css'],\n",
              " [],\n",
              " ['c#'],\n",
              " ['c'],\n",
              " [],\n",
              " [],\n",
              " ['windows', 'windows-7'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['java'],\n",
              " ['windows'],\n",
              " [],\n",
              " ['c#', 'wpf'],\n",
              " [],\n",
              " ['c#'],\n",
              " [],\n",
              " ['javascript', 'xml', 'ajax', 'forms'],\n",
              " [],\n",
              " ['c#', 'web-services'],\n",
              " [],\n",
              " ['java', 'android'],\n",
              " ['c++', 'windows'],\n",
              " ['css'],\n",
              " ['windows'],\n",
              " [],\n",
              " ['android'],\n",
              " [],\n",
              " ['python'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['javascript', 'iphone'],\n",
              " ['javascript', 'forms'],\n",
              " [],\n",
              " ['jquery', 'html', 'css', 'forms'],\n",
              " [],\n",
              " ['c#', '.net'],\n",
              " ['android'],\n",
              " ['android', 'database'],\n",
              " [],\n",
              " ['java', 'hibernate'],\n",
              " ['java'],\n",
              " ['c#', '.net'],\n",
              " ['android'],\n",
              " ['windows', 'java'],\n",
              " ['c++'],\n",
              " ['android'],\n",
              " ['ios'],\n",
              " [],\n",
              " ['windows'],\n",
              " [],\n",
              " [],\n",
              " ['python'],\n",
              " [],\n",
              " ['c#', '.net'],\n",
              " ['android', 'sql', 'performance'],\n",
              " ['java', 'xml'],\n",
              " [],\n",
              " ['android'],\n",
              " ['sql', 'sql-server'],\n",
              " ['java'],\n",
              " ['android'],\n",
              " ['python', 'django', 'google-app-engine'],\n",
              " ['asp.net'],\n",
              " ['html', 'css'],\n",
              " ['php', 'mysql'],\n",
              " ['php'],\n",
              " ['iphone'],\n",
              " ['python', 'django'],\n",
              " ['c#', 'asp.net'],\n",
              " ['java'],\n",
              " ['bash'],\n",
              " [],\n",
              " ['ios'],\n",
              " [],\n",
              " ['mysql', 'database'],\n",
              " ['windows', 'performance'],\n",
              " ['ios'],\n",
              " ['javascript', 'jquery', 'html'],\n",
              " ['php'],\n",
              " [],\n",
              " ['iphone'],\n",
              " ['html5'],\n",
              " ['sql', 'sql-server'],\n",
              " ['c++'],\n",
              " [],\n",
              " ['sql', 'sql-server'],\n",
              " ['iphone'],\n",
              " [],\n",
              " ['php'],\n",
              " ['python'],\n",
              " ['sql-server', 'vb.net', 'winforms'],\n",
              " ['xml'],\n",
              " ['java', 'android'],\n",
              " ['html', 'css'],\n",
              " ['c'],\n",
              " [],\n",
              " ['c'],\n",
              " [],\n",
              " ['html', 'css'],\n",
              " ['android', 'ios'],\n",
              " [],\n",
              " ['php', 'objective-c'],\n",
              " [],\n",
              " ['android'],\n",
              " ['windows'],\n",
              " ['algorithm', 'performance'],\n",
              " [],\n",
              " ['java', 'hibernate'],\n",
              " ['java'],\n",
              " [],\n",
              " ['php', 'html'],\n",
              " ['php'],\n",
              " [],\n",
              " [],\n",
              " ['ios'],\n",
              " ['android', 'json'],\n",
              " [],\n",
              " ['iphone', 'objective-c', 'ios'],\n",
              " ['git'],\n",
              " ['perl'],\n",
              " ['regex'],\n",
              " ['html', 'css'],\n",
              " ['javascript', 'jquery'],\n",
              " ['sql'],\n",
              " ['performance', 'hibernate'],\n",
              " ['jquery'],\n",
              " ['javascript'],\n",
              " [],\n",
              " ['c#'],\n",
              " ['c++'],\n",
              " ['asp.net-mvc'],\n",
              " ['android'],\n",
              " ['java'],\n",
              " ['python'],\n",
              " [],\n",
              " ['android'],\n",
              " [],\n",
              " [],\n",
              " ['php'],\n",
              " [],\n",
              " ['java', 'swing'],\n",
              " ['java', 'android'],\n",
              " ['c++', 'c', 'arrays'],\n",
              " ['java', 'linux', 'windows', 'swing'],\n",
              " ['html', 'css'],\n",
              " ['python'],\n",
              " [],\n",
              " ['java'],\n",
              " ['c++'],\n",
              " ['linux'],\n",
              " ['c++'],\n",
              " [],\n",
              " ['php'],\n",
              " ['jquery', 'ruby-on-rails-3', 'forms'],\n",
              " ['windows'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['javascript', 'jquery'],\n",
              " ['sql'],\n",
              " ['android'],\n",
              " ['java', 'swing'],\n",
              " ['android'],\n",
              " [],\n",
              " ['.net'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['linux', 'database'],\n",
              " ['c#'],\n",
              " ['iphone'],\n",
              " ['objective-c'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['iphone', 'objective-c'],\n",
              " [],\n",
              " ['javascript', 'html5'],\n",
              " ['ruby-on-rails'],\n",
              " ['php'],\n",
              " [],\n",
              " ['linux', 'java'],\n",
              " ['c++'],\n",
              " ['javascript', 'jquery'],\n",
              " [],\n",
              " [],\n",
              " ['osx'],\n",
              " ['java'],\n",
              " ['performance'],\n",
              " ['php', 'sql'],\n",
              " ['xml'],\n",
              " ['windows'],\n",
              " ['iphone', 'objective-c'],\n",
              " [],\n",
              " ['c#'],\n",
              " ['windows-7'],\n",
              " ['php'],\n",
              " ['java', 'xml'],\n",
              " ['php', 'javascript', 'ajax'],\n",
              " ['java'],\n",
              " ['c#', '.net'],\n",
              " ['java', 'html', 'xml'],\n",
              " [],\n",
              " ['java', 'swing'],\n",
              " ['javascript', 'html'],\n",
              " [],\n",
              " ['ruby-on-rails', 'ruby'],\n",
              " ['c#', 'hibernate'],\n",
              " ['ruby-on-rails', 'ruby', 'ruby-on-rails-3'],\n",
              " [],\n",
              " ['javascript'],\n",
              " ['javascript'],\n",
              " ['android'],\n",
              " ['iphone', 'objective-c'],\n",
              " ['sql-server'],\n",
              " ['perl', 'performance'],\n",
              " ['c++', 'linux'],\n",
              " ['python'],\n",
              " ['android'],\n",
              " ['android'],\n",
              " [],\n",
              " ['php'],\n",
              " [],\n",
              " ['c#'],\n",
              " [],\n",
              " [],\n",
              " ['ios'],\n",
              " ['php', 'ajax'],\n",
              " ['android'],\n",
              " ['iphone'],\n",
              " [],\n",
              " ['java'],\n",
              " ['regex'],\n",
              " ['mysql'],\n",
              " [],\n",
              " [],\n",
              " ['c#', 'asp.net-mvc'],\n",
              " ['c#'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['java'],\n",
              " ['json'],\n",
              " ['winforms'],\n",
              " ['performance'],\n",
              " ['android'],\n",
              " ['java'],\n",
              " ['ubuntu'],\n",
              " [],\n",
              " ['eclipse', 'google-app-engine', 'osx'],\n",
              " ['asp.net'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['perl'],\n",
              " ['python'],\n",
              " [],\n",
              " [],\n",
              " ['html', 'ios'],\n",
              " ['java'],\n",
              " ['c++'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['php', '.net'],\n",
              " ['css'],\n",
              " ['c#', '.net'],\n",
              " ['javascript', 'html'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['java'],\n",
              " [],\n",
              " ['c#'],\n",
              " [],\n",
              " [],\n",
              " ['c#', '.net'],\n",
              " [],\n",
              " ['linux', 'ubuntu'],\n",
              " ['c#'],\n",
              " [],\n",
              " ['java'],\n",
              " [],\n",
              " [],\n",
              " ['php'],\n",
              " ['c#', 'asp.net-mvc'],\n",
              " ['iphone'],\n",
              " [],\n",
              " ['objective-c', 'ios'],\n",
              " [],\n",
              " ['ruby'],\n",
              " ['php', 'arrays'],\n",
              " ['iphone'],\n",
              " ['iphone', 'objective-c'],\n",
              " ['c'],\n",
              " ['c++'],\n",
              " ['hibernate'],\n",
              " [],\n",
              " ['bash'],\n",
              " ['iphone', 'objective-c'],\n",
              " ['python'],\n",
              " ['java'],\n",
              " ['java', 'android', 'arrays'],\n",
              " ['mysql'],\n",
              " ['vb.net'],\n",
              " ['java'],\n",
              " ['android'],\n",
              " [],\n",
              " [],\n",
              " ['iphone'],\n",
              " ['java', 'regex'],\n",
              " ['java'],\n",
              " ['java', 'javascript'],\n",
              " ['iphone', 'objective-c'],\n",
              " [],\n",
              " ['php', 'mysql'],\n",
              " [],\n",
              " [],\n",
              " ['iphone', 'ios'],\n",
              " ['c#', '.net'],\n",
              " [],\n",
              " [],\n",
              " ['android', 'json', 'web-services'],\n",
              " [],\n",
              " ['php'],\n",
              " ['javascript', 'jquery'],\n",
              " ['ruby-on-rails', 'ruby'],\n",
              " ['git'],\n",
              " [],\n",
              " ['c++'],\n",
              " ['c#', 'wpf'],\n",
              " ['python', 'regex', 'django'],\n",
              " [],\n",
              " [],\n",
              " ['c#', '.net'],\n",
              " ['vb.net'],\n",
              " ['iphone'],\n",
              " [],\n",
              " [],\n",
              " ['jquery'],\n",
              " [],\n",
              " ['android'],\n",
              " ['c#', '.net'],\n",
              " ['c#'],\n",
              " ['java'],\n",
              " ['javascript'],\n",
              " [],\n",
              " ['c#', 'asp.net', 'vb.net'],\n",
              " ['jquery', 'html', 'css'],\n",
              " [],\n",
              " ['android'],\n",
              " ['windows-7'],\n",
              " ['linux'],\n",
              " ['python', 'json', 'google-app-engine'],\n",
              " ['jquery'],\n",
              " [],\n",
              " [],\n",
              " ['algorithm'],\n",
              " [],\n",
              " ['java'],\n",
              " ['jquery'],\n",
              " [],\n",
              " ['jquery'],\n",
              " ['java'],\n",
              " [],\n",
              " [],\n",
              " ['javascript', 'mysql', 'ajax'],\n",
              " ['.net', 'c++'],\n",
              " ['ios'],\n",
              " [],\n",
              " ['wpf'],\n",
              " ['java'],\n",
              " ['javascript', 'jquery', 'html'],\n",
              " ['mysql'],\n",
              " ['asp.net', 'vb.net'],\n",
              " [],\n",
              " [],\n",
              " ['php', 'javascript'],\n",
              " ['c#', '.net'],\n",
              " ['c#'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['php'],\n",
              " [],\n",
              " [],\n",
              " ['mysql'],\n",
              " [],\n",
              " ['php', 'mysql'],\n",
              " ['windows'],\n",
              " ['java'],\n",
              " ['html'],\n",
              " [],\n",
              " [],\n",
              " ['git'],\n",
              " ['windows', 'windows-7'],\n",
              " [],\n",
              " ['c', 'performance'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['java', '.net', 'web-services'],\n",
              " [],\n",
              " [],\n",
              " ['django'],\n",
              " [],\n",
              " ['asp.net'],\n",
              " ['c', 'windows'],\n",
              " [],\n",
              " [],\n",
              " ['java'],\n",
              " ['java'],\n",
              " [],\n",
              " ['java'],\n",
              " ['php'],\n",
              " ['ios'],\n",
              " [],\n",
              " [],\n",
              " ['java', 'swing'],\n",
              " [],\n",
              " ['asp.net'],\n",
              " ['java'],\n",
              " ['css'],\n",
              " ['html'],\n",
              " [],\n",
              " ['c++'],\n",
              " ['php', 'html'],\n",
              " ['c++'],\n",
              " [],\n",
              " [],\n",
              " ['sql-server'],\n",
              " ['ruby-on-rails', 'ruby-on-rails-3'],\n",
              " [],\n",
              " ['javascript'],\n",
              " ['c++'],\n",
              " [],\n",
              " [],\n",
              " ['c#', '.net'],\n",
              " [],\n",
              " ['java'],\n",
              " ['php', 'arrays'],\n",
              " ['osx'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['wpf'],\n",
              " ['android'],\n",
              " ['java', 'c++'],\n",
              " [],\n",
              " [],\n",
              " ['java', 'mysql'],\n",
              " [],\n",
              " ['windows'],\n",
              " ['c#'],\n",
              " ['c#', '.net', 'vb.net'],\n",
              " ['javascript', 'json'],\n",
              " ['asp.net-mvc'],\n",
              " ['java'],\n",
              " [],\n",
              " ['android', 'iphone', 'ios'],\n",
              " [],\n",
              " ['sql-server'],\n",
              " ['php', 'mysql'],\n",
              " ['html'],\n",
              " ['linux'],\n",
              " ['javascript'],\n",
              " [],\n",
              " ['ruby'],\n",
              " ['python'],\n",
              " ['ubuntu'],\n",
              " ['java', 'swing'],\n",
              " ['java', 'xml'],\n",
              " ['json'],\n",
              " ['php'],\n",
              " ['android'],\n",
              " [],\n",
              " ['c#', 'web-services'],\n",
              " ['linux', 'bash'],\n",
              " ['arrays'],\n",
              " [],\n",
              " [],\n",
              " ['c#', 'asp.net-mvc'],\n",
              " ['c++'],\n",
              " ['python'],\n",
              " ['asp.net-mvc'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['php'],\n",
              " [],\n",
              " ['javascript'],\n",
              " ['android'],\n",
              " ['.net'],\n",
              " [],\n",
              " ['c++', 'performance'],\n",
              " ['php', 'jquery', 'ajax'],\n",
              " [],\n",
              " [],\n",
              " ['c#'],\n",
              " ['jquery', 'ajax'],\n",
              " ['c++', 'windows', 'json'],\n",
              " ['iphone', 'ios'],\n",
              " ['php', 'javascript'],\n",
              " ['javascript', 'jquery'],\n",
              " ['c'],\n",
              " [],\n",
              " ['java'],\n",
              " ['java', 'swing'],\n",
              " [],\n",
              " ['ajax', 'hibernate'],\n",
              " ['iphone', 'objective-c'],\n",
              " [],\n",
              " ['javascript'],\n",
              " ['iphone'],\n",
              " [],\n",
              " ['c++'],\n",
              " ['ruby-on-rails-3'],\n",
              " ['ruby-on-rails', 'ruby'],\n",
              " [],\n",
              " ['.net'],\n",
              " ['c++', 'c'],\n",
              " ['django'],\n",
              " ['java'],\n",
              " ['javascript', 'jquery', 'html5'],\n",
              " [],\n",
              " [],\n",
              " ['javascript'],\n",
              " ['mysql', 'ruby', 'ruby-on-rails-3'],\n",
              " ['ajax', 'json'],\n",
              " [],\n",
              " ['iphone', 'objective-c'],\n",
              " ['algorithm'],\n",
              " [],\n",
              " ['database'],\n",
              " [],\n",
              " ['.net', 'winforms'],\n",
              " ['html', 'css'],\n",
              " ['django'],\n",
              " ['php'],\n",
              " ['javascript', 'arrays'],\n",
              " ['c'],\n",
              " [],\n",
              " ['json'],\n",
              " ['jquery'],\n",
              " ['c#', '.net', 'winforms'],\n",
              " [],\n",
              " [],\n",
              " ['python'],\n",
              " ['android'],\n",
              " ['ruby'],\n",
              " ['php', 'regex'],\n",
              " ['c#'],\n",
              " [],\n",
              " ['android'],\n",
              " ['iphone'],\n",
              " [],\n",
              " ['linux'],\n",
              " ['javascript'],\n",
              " [],\n",
              " [],\n",
              " ['java'],\n",
              " [],\n",
              " ['java', 'arrays', 'swing'],\n",
              " ['python'],\n",
              " ['ruby', 'git'],\n",
              " [],\n",
              " ['html', 'css'],\n",
              " ['html', 'css'],\n",
              " ['c#', 'asp.net'],\n",
              " [],\n",
              " ['c#', 'xml', 'arrays'],\n",
              " [],\n",
              " ['iphone', 'objective-c'],\n",
              " [],\n",
              " ['ruby-on-rails'],\n",
              " ['ruby-on-rails', 'ruby'],\n",
              " ['python'],\n",
              " ['asp.net'],\n",
              " [],\n",
              " ['python', 'google-app-engine'],\n",
              " ['php'],\n",
              " ['python'],\n",
              " [],\n",
              " ['bash'],\n",
              " ['c++'],\n",
              " ['android'],\n",
              " ['java', 'sql-server', 'hibernate'],\n",
              " ['java'],\n",
              " ['ios', 'performance'],\n",
              " ['java'],\n",
              " ['iphone', 'objective-c'],\n",
              " ['ubuntu'],\n",
              " ['c#'],\n",
              " ['android'],\n",
              " ['c++'],\n",
              " ['php'],\n",
              " ['javascript'],\n",
              " ['html5'],\n",
              " ['c#'],\n",
              " ['c++', 'performance'],\n",
              " ['python'],\n",
              " [],\n",
              " ['mysql'],\n",
              " ['regex'],\n",
              " ['php'],\n",
              " ['html5'],\n",
              " ['ruby-on-rails', 'regex'],\n",
              " ['java'],\n",
              " ['javascript'],\n",
              " ['php'],\n",
              " [],\n",
              " [],\n",
              " ['android'],\n",
              " [],\n",
              " ['php'],\n",
              " [],\n",
              " ['jquery'],\n",
              " ['winforms'],\n",
              " [],\n",
              " ['java'],\n",
              " ['c'],\n",
              " ['java', 'android'],\n",
              " ['c#', '.net', 'regex'],\n",
              " ['android'],\n",
              " [],\n",
              " ['c#'],\n",
              " ['java'],\n",
              " ['java', 'c'],\n",
              " ['java', 'android', 'sql'],\n",
              " ['javascript', 'regex'],\n",
              " [],\n",
              " [],\n",
              " ['c#'],\n",
              " [],\n",
              " ['android'],\n",
              " ['performance'],\n",
              " ['c'],\n",
              " ['asp.net'],\n",
              " ['java'],\n",
              " ['java', 'swing'],\n",
              " ['jquery'],\n",
              " ['css'],\n",
              " ['winforms'],\n",
              " [],\n",
              " ['php'],\n",
              " ['asp.net'],\n",
              " [],\n",
              " [],\n",
              " ['c'],\n",
              " [],\n",
              " ['php'],\n",
              " ['python'],\n",
              " ['android'],\n",
              " ['ios'],\n",
              " ['android'],\n",
              " ['database'],\n",
              " ['ruby-on-rails', 'ruby'],\n",
              " ['c#', 'html'],\n",
              " ['php'],\n",
              " ['mysql', 'sql'],\n",
              " ['php', 'mysql'],\n",
              " ['git'],\n",
              " [],\n",
              " ['javascript', 'jquery'],\n",
              " [],\n",
              " ['iphone', 'web-services', 'google-app-engine', 'ios'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['wpf'],\n",
              " ['iphone', 'objective-c'],\n",
              " [],\n",
              " ['python'],\n",
              " ['android'],\n",
              " ['php'],\n",
              " ['html', 'css'],\n",
              " ['php'],\n",
              " ['windows-7'],\n",
              " ['python'],\n",
              " [],\n",
              " [],\n",
              " ['c#', 'wpf'],\n",
              " [],\n",
              " ['ruby-on-rails', 'ruby-on-rails-3'],\n",
              " ['python', 'regex'],\n",
              " ['java'],\n",
              " ['asp.net'],\n",
              " ['c#'],\n",
              " ['c++'],\n",
              " [],\n",
              " ['javascript', 'html'],\n",
              " ['c#', '.net'],\n",
              " ['php', 'mysql'],\n",
              " ['c++', 'windows'],\n",
              " [],\n",
              " ['ruby'],\n",
              " [],\n",
              " ['javascript', 'jquery', 'ajax'],\n",
              " ['php', 'html'],\n",
              " ['android', 'html'],\n",
              " ['java', 'database', 'hibernate'],\n",
              " ['java'],\n",
              " ['c#'],\n",
              " ['javascript'],\n",
              " ['c#'],\n",
              " ['mysql'],\n",
              " ['iphone'],\n",
              " ['ruby', 'linux'],\n",
              " ['java'],\n",
              " ['android'],\n",
              " [],\n",
              " ['java'],\n",
              " ['html', 'css'],\n",
              " ['ios', 'osx'],\n",
              " ['java', 'swing'],\n",
              " [],\n",
              " ['ruby-on-rails-3', 'json'],\n",
              " ['c#'],\n",
              " ['php', 'mysql'],\n",
              " ['javascript'],\n",
              " ['php'],\n",
              " ['ubuntu'],\n",
              " [],\n",
              " ['java'],\n",
              " ['java', 'android'],\n",
              " ['asp.net', 'vb.net'],\n",
              " [],\n",
              " ['c++'],\n",
              " ['c#'],\n",
              " ['git'],\n",
              " [],\n",
              " ['c++'],\n",
              " ['algorithm'],\n",
              " ['iphone'],\n",
              " ['android'],\n",
              " ['linux'],\n",
              " ['android'],\n",
              " ['git'],\n",
              " ['c#', 'asp.net', 'mysql', 'ajax'],\n",
              " ['python'],\n",
              " ['python'],\n",
              " ['c#', 'winforms'],\n",
              " [],\n",
              " ['java', 'xml'],\n",
              " ['asp.net', 'asp.net-mvc'],\n",
              " [],\n",
              " ['c#', 'asp.net', 'ajax'],\n",
              " [],\n",
              " ['iphone', 'ios'],\n",
              " [],\n",
              " ['ruby', 'ajax'],\n",
              " [],\n",
              " ['git'],\n",
              " ['javascript', 'html', 'google-app-engine'],\n",
              " ['jquery'],\n",
              " ['xml'],\n",
              " ['wpf'],\n",
              " ['php'],\n",
              " ['linux'],\n",
              " [],\n",
              " [],\n",
              " ['c#', 'regex'],\n",
              " ['javascript', 'html'],\n",
              " ['iphone', 'ios'],\n",
              " ['jquery', 'arrays'],\n",
              " ['jquery', 'json'],\n",
              " ['forms'],\n",
              " ['ios'],\n",
              " ['python'],\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9MG0wKLoJDF"
      },
      "source": [
        "#Making a dictionary of word tags #TRAIN\n",
        "test.Tags = test.Tags.apply(lambda x: str(x).split())\n",
        "test_tag_freq_dict = {}\n",
        "for tags in test.Tags:\n",
        "    for tag in tags:\n",
        "        if tag not in test_tag_freq_dict:\n",
        "            test_tag_freq_dict[tag] = 0\n",
        "        else:\n",
        "            test_tag_freq_dict[tag] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M0_x3rloI_l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e9a1646-b340-48c7-cbe5-faa7e7348de9"
      },
      "source": [
        "# Get most common tags\n",
        "tags_to_use = 50 #was 200\n",
        "test_tag_freq_dict_sorted = dict(sorted(test_tag_freq_dict.items(), key=lambda x: x[1], reverse=True))\n",
        "test_final_tags = list(test_tag_freq_dict_sorted.keys())[:tags_to_use]\n",
        "len(test_final_tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcVC9ymdoI8N"
      },
      "source": [
        "# Change tag data to only for final_tags\n",
        "test_final_tag_data = []\n",
        "for tags in test.Tags:\n",
        "    temp = []\n",
        "    for tag in tags:\n",
        "        if tag in test_final_tags:\n",
        "            temp.append(tag)\n",
        "    test_final_tag_data.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR4_rDc6oI36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8d5e498-2e80-4493-e122-9a747a7c677a"
      },
      "source": [
        "test_final_tag_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [],\n",
              " ['c#'],\n",
              " ['php', 'ajax'],\n",
              " [],\n",
              " ['asp.net-mvc'],\n",
              " ['html'],\n",
              " [],\n",
              " ['iphone', 'objective-c', 'ios'],\n",
              " ['ios'],\n",
              " ['networking'],\n",
              " [],\n",
              " ['javascript', 'regex'],\n",
              " [],\n",
              " [],\n",
              " ['html', 'css'],\n",
              " ['java'],\n",
              " ['c++'],\n",
              " ['android'],\n",
              " ['asp.net-mvc'],\n",
              " [],\n",
              " [],\n",
              " ['html'],\n",
              " ['jquery'],\n",
              " ['database'],\n",
              " ['javascript', 'jquery'],\n",
              " [],\n",
              " [],\n",
              " ['python'],\n",
              " [],\n",
              " ['java'],\n",
              " ['php', 'mysql', 'database'],\n",
              " ['php', 'jquery'],\n",
              " ['java'],\n",
              " ['ruby'],\n",
              " ['python', 'django'],\n",
              " ['java'],\n",
              " ['c#', 'visual-studio-2010'],\n",
              " ['javascript', 'ruby-on-rails', 'ruby'],\n",
              " ['jquery'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['c++'],\n",
              " ['php'],\n",
              " ['c#', 'multithreading'],\n",
              " ['sql', 'ruby-on-rails', 'ruby-on-rails-3'],\n",
              " [],\n",
              " ['java'],\n",
              " ['php'],\n",
              " ['python'],\n",
              " [],\n",
              " ['iphone'],\n",
              " [],\n",
              " ['java'],\n",
              " ['xml', 'string'],\n",
              " [],\n",
              " [],\n",
              " ['javascript', 'asp.net'],\n",
              " ['osx'],\n",
              " ['wcf'],\n",
              " [],\n",
              " ['android'],\n",
              " ['c++'],\n",
              " ['jquery', 'html5'],\n",
              " ['c'],\n",
              " ['java'],\n",
              " ['python'],\n",
              " ['javascript'],\n",
              " ['c#'],\n",
              " ['asp.net', 'asp.net-mvc'],\n",
              " ['python', 'osx'],\n",
              " ['iphone'],\n",
              " [],\n",
              " ['java', 'android'],\n",
              " [],\n",
              " [],\n",
              " ['java'],\n",
              " ['ios'],\n",
              " ['android'],\n",
              " ['ruby', 'security'],\n",
              " ['networking'],\n",
              " ['python'],\n",
              " [],\n",
              " ['mysql'],\n",
              " ['windows-7'],\n",
              " [],\n",
              " ['c#'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['php'],\n",
              " [],\n",
              " ['java'],\n",
              " ['c#'],\n",
              " ['facebook'],\n",
              " ['linux'],\n",
              " ['php'],\n",
              " ['php', 'arrays'],\n",
              " ['windows-7'],\n",
              " ['c#', 'vb.net'],\n",
              " ['php', 'javascript'],\n",
              " ['iphone', 'osx'],\n",
              " ['c#', '.net', 'multithreading'],\n",
              " [],\n",
              " [],\n",
              " ['css'],\n",
              " [],\n",
              " ['c++'],\n",
              " ['windows-7'],\n",
              " ['c#'],\n",
              " ['java'],\n",
              " ['ios'],\n",
              " ['mysql'],\n",
              " ['c#'],\n",
              " ['android'],\n",
              " ['android', 'facebook'],\n",
              " ['ios', 'xcode'],\n",
              " ['iphone', 'ios'],\n",
              " [],\n",
              " ['android'],\n",
              " ['objective-c', 'ios'],\n",
              " [],\n",
              " [],\n",
              " ['php', 'mysql'],\n",
              " ['java'],\n",
              " ['c#', 'xml'],\n",
              " ['java'],\n",
              " [],\n",
              " [],\n",
              " ['javascript', 'jquery'],\n",
              " ['html', 'css'],\n",
              " ['c#', '.net', 'wpf'],\n",
              " [],\n",
              " ['javascript'],\n",
              " ['javascript'],\n",
              " ['c#'],\n",
              " [],\n",
              " ['visual-studio-2010'],\n",
              " ['iphone'],\n",
              " ['iphone', 'ios', 'xcode'],\n",
              " ['java'],\n",
              " ['javascript'],\n",
              " ['php', 'jquery', 'ajax'],\n",
              " ['javascript', 'json'],\n",
              " [],\n",
              " ['python', 'regex'],\n",
              " ['javascript', 'jquery'],\n",
              " ['javascript', 'regex'],\n",
              " [],\n",
              " ['java'],\n",
              " ['javascript', 'html', 'css'],\n",
              " ['ios'],\n",
              " [],\n",
              " ['html'],\n",
              " [],\n",
              " ['php', 'mysql'],\n",
              " ['java', 'wpf'],\n",
              " ['javascript', 'jquery'],\n",
              " [],\n",
              " ['php'],\n",
              " [],\n",
              " ['php'],\n",
              " [],\n",
              " ['java'],\n",
              " ['jquery'],\n",
              " [],\n",
              " ['javascript', 'jquery', 'html', 'css'],\n",
              " ['vb.net'],\n",
              " [],\n",
              " ['.net'],\n",
              " ['networking'],\n",
              " ['c++'],\n",
              " [],\n",
              " ['ruby-on-rails'],\n",
              " [],\n",
              " ['python', 'django'],\n",
              " [],\n",
              " ['asp.net-mvc-3'],\n",
              " [],\n",
              " ['sql-server'],\n",
              " ['php'],\n",
              " ['python'],\n",
              " ['php'],\n",
              " [],\n",
              " ['java'],\n",
              " ['javascript'],\n",
              " [],\n",
              " ['mysql', 'sql', 'database'],\n",
              " ['php'],\n",
              " ['xml'],\n",
              " ['android'],\n",
              " ['asp.net-mvc'],\n",
              " ['c#'],\n",
              " ['asp.net', 'javascript'],\n",
              " ['android'],\n",
              " [],\n",
              " [],\n",
              " ['iphone', 'objective-c'],\n",
              " [],\n",
              " ['asp.net'],\n",
              " [],\n",
              " ['ios'],\n",
              " [],\n",
              " ['android'],\n",
              " ['python'],\n",
              " [],\n",
              " [],\n",
              " ['python'],\n",
              " ['windows'],\n",
              " [],\n",
              " ['c#'],\n",
              " ['c'],\n",
              " ['ruby-on-rails', 'ruby'],\n",
              " [],\n",
              " ['c#', 'c++'],\n",
              " [],\n",
              " ['c#', 'sql', 'sql-server'],\n",
              " [],\n",
              " ['windows'],\n",
              " ['c#', '.net', 'regex'],\n",
              " ['osx'],\n",
              " [],\n",
              " ['.net'],\n",
              " ['java'],\n",
              " ['mysql'],\n",
              " ['ruby-on-rails'],\n",
              " ['c', 'linux'],\n",
              " ['ruby'],\n",
              " ['android'],\n",
              " [],\n",
              " ['c++', 'linux'],\n",
              " [],\n",
              " ['javascript', 'jquery'],\n",
              " [],\n",
              " ['java'],\n",
              " [],\n",
              " ['linux'],\n",
              " ['c#', 'java'],\n",
              " ['python'],\n",
              " [],\n",
              " ['php', 'mysql'],\n",
              " ['php'],\n",
              " [],\n",
              " ['java'],\n",
              " ['ios'],\n",
              " [],\n",
              " ['windows'],\n",
              " ['objective-c'],\n",
              " ['vb.net'],\n",
              " ['java'],\n",
              " ['json'],\n",
              " [],\n",
              " ['jquery'],\n",
              " [],\n",
              " ['windows-7'],\n",
              " [],\n",
              " [],\n",
              " ['c++'],\n",
              " ['javascript'],\n",
              " ['java', 'eclipse'],\n",
              " ['android'],\n",
              " ['windows-7'],\n",
              " ['javascript'],\n",
              " [],\n",
              " [],\n",
              " ['mysql', 'performance'],\n",
              " [],\n",
              " ['android'],\n",
              " ['javascript'],\n",
              " ['ruby-on-rails-3'],\n",
              " ['c#', '.net', 'asp.net', 'string'],\n",
              " [],\n",
              " [],\n",
              " ['networking'],\n",
              " [],\n",
              " [],\n",
              " ['android'],\n",
              " [],\n",
              " ['c#'],\n",
              " ['php'],\n",
              " ['ubuntu'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['java', 'android'],\n",
              " ['json'],\n",
              " ['c#', 'asp.net'],\n",
              " ['java', 'networking'],\n",
              " ['ruby-on-rails'],\n",
              " [],\n",
              " ['javascript', 'jquery'],\n",
              " ['c++', 'windows', 'linux'],\n",
              " [],\n",
              " ['php'],\n",
              " [],\n",
              " ['python'],\n",
              " [],\n",
              " ['c++'],\n",
              " ['mysql'],\n",
              " ['ruby-on-rails'],\n",
              " ['php'],\n",
              " ['c#', 'asp.net', 'database', 'json'],\n",
              " ['c#'],\n",
              " ['objective-c', 'ios'],\n",
              " [],\n",
              " ['mysql'],\n",
              " ['ruby-on-rails', 'ruby-on-rails-3'],\n",
              " [],\n",
              " ['objective-c'],\n",
              " [],\n",
              " [],\n",
              " ['python'],\n",
              " ['jquery'],\n",
              " ['android'],\n",
              " [],\n",
              " ['ios', 'xcode'],\n",
              " [],\n",
              " ['cocoa'],\n",
              " [],\n",
              " ['c#'],\n",
              " [],\n",
              " ['php', 'regex'],\n",
              " ['objective-c', 'cocoa'],\n",
              " ['javascript', 'jquery', 'html'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['php'],\n",
              " ['c++', 'regex'],\n",
              " ['java', 'android'],\n",
              " ['android'],\n",
              " ['ruby-on-rails', 'ruby-on-rails-3'],\n",
              " ['python', 'multithreading'],\n",
              " ['java', 'android'],\n",
              " ['python'],\n",
              " ['php', 'mysql'],\n",
              " ['jquery'],\n",
              " ['css', 'ruby-on-rails'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['mysql', 'ruby'],\n",
              " ['php'],\n",
              " ['iphone'],\n",
              " ['css'],\n",
              " ['java'],\n",
              " [],\n",
              " [],\n",
              " ['jquery'],\n",
              " ['ios', 'xcode'],\n",
              " ['ios', 'xcode', 'osx'],\n",
              " ['java'],\n",
              " ['c++'],\n",
              " ['c#', 'wcf'],\n",
              " ['ruby-on-rails'],\n",
              " ['wpf'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['c#'],\n",
              " ['c#'],\n",
              " ['iphone', 'ios', 'objective-c', 'cocoa'],\n",
              " ['java', 'eclipse'],\n",
              " ['windows-7'],\n",
              " ['php', 'regex'],\n",
              " ['php'],\n",
              " ['facebook'],\n",
              " ['html', 'css'],\n",
              " ['python'],\n",
              " [],\n",
              " ['c#'],\n",
              " [],\n",
              " ['linux'],\n",
              " ['ruby'],\n",
              " ['c#', 'asp.net'],\n",
              " ['c#', 'javascript', 'asp.net'],\n",
              " [],\n",
              " ['java'],\n",
              " ['python'],\n",
              " ['javascript'],\n",
              " ['python'],\n",
              " ['c++'],\n",
              " ['android'],\n",
              " ['jquery'],\n",
              " [],\n",
              " ['sql'],\n",
              " [],\n",
              " ['java'],\n",
              " [],\n",
              " [],\n",
              " ['android'],\n",
              " ['mysql', 'database'],\n",
              " ['security'],\n",
              " ['java', 'html'],\n",
              " ['java'],\n",
              " [],\n",
              " ['c#'],\n",
              " ['javascript', 'jquery'],\n",
              " [],\n",
              " [],\n",
              " ['javascript'],\n",
              " ['.net'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['php'],\n",
              " [],\n",
              " ['c#', 'xml'],\n",
              " ['windows-7'],\n",
              " ['windows', 'ubuntu'],\n",
              " ['python', 'html'],\n",
              " [],\n",
              " ['asp.net'],\n",
              " ['c#'],\n",
              " ['.net'],\n",
              " [],\n",
              " ['c#', 'sql-server'],\n",
              " ['.net'],\n",
              " ['windows'],\n",
              " ['java', 'arrays'],\n",
              " ['c++', 'linux'],\n",
              " ['python', 'string'],\n",
              " ['java'],\n",
              " ['php'],\n",
              " ['c#'],\n",
              " [],\n",
              " ['java', 'android'],\n",
              " ['facebook'],\n",
              " [],\n",
              " [],\n",
              " ['objective-c'],\n",
              " [],\n",
              " ['osx'],\n",
              " ['c#'],\n",
              " ['c++'],\n",
              " ['asp.net'],\n",
              " ['iphone'],\n",
              " [],\n",
              " ['c++'],\n",
              " ['java', 'android', 'eclipse'],\n",
              " ['regex'],\n",
              " ['javascript', 'html', 'html5'],\n",
              " ['vb.net'],\n",
              " ['php', 'mysql'],\n",
              " ['java', 'ruby-on-rails', 'ruby'],\n",
              " ['c#', 'wcf'],\n",
              " ['php', 'javascript', 'json'],\n",
              " ['objective-c', 'cocoa'],\n",
              " ['python', 'django'],\n",
              " ['c#'],\n",
              " [],\n",
              " ['javascript'],\n",
              " ['c#'],\n",
              " ['java'],\n",
              " ['facebook', 'asp.net-mvc-3'],\n",
              " ['c#'],\n",
              " [],\n",
              " ['java'],\n",
              " [],\n",
              " ['html', 'css'],\n",
              " ['windows-7'],\n",
              " [],\n",
              " ['c#', 'asp.net', 'asp.net-mvc-3'],\n",
              " ['asp.net-mvc'],\n",
              " [],\n",
              " ['android'],\n",
              " ['python'],\n",
              " ['android'],\n",
              " [],\n",
              " ['jquery', 'html'],\n",
              " [],\n",
              " [],\n",
              " ['java'],\n",
              " ['windows'],\n",
              " ['asp.net'],\n",
              " ['javascript', 'jquery', 'html', 'css'],\n",
              " ['asp.net'],\n",
              " [],\n",
              " ['iphone', 'ios'],\n",
              " ['java'],\n",
              " [],\n",
              " ['ios'],\n",
              " [],\n",
              " ['ruby-on-rails'],\n",
              " ['ios'],\n",
              " [],\n",
              " ['php'],\n",
              " ['c#'],\n",
              " [],\n",
              " ['c#', 'asp.net'],\n",
              " [],\n",
              " [],\n",
              " ['python'],\n",
              " ['python'],\n",
              " ['php'],\n",
              " ['.net'],\n",
              " [],\n",
              " [],\n",
              " ['javascript', 'jquery'],\n",
              " ['iphone', 'ios'],\n",
              " ['sql', 'sql-server'],\n",
              " [],\n",
              " ['c#', 'asp.net'],\n",
              " ['android'],\n",
              " ['c#', 'asp.net'],\n",
              " ['iphone', 'objective-c', 'facebook'],\n",
              " ['ruby-on-rails'],\n",
              " ['iphone'],\n",
              " ['android'],\n",
              " ['iphone'],\n",
              " ['c++'],\n",
              " ['mysql'],\n",
              " ['java', 'multithreading'],\n",
              " [],\n",
              " [],\n",
              " ['asp.net-mvc'],\n",
              " [],\n",
              " ['linux'],\n",
              " ['c#', 'asp.net', 'wcf'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['jquery'],\n",
              " ['c#'],\n",
              " ['c#', '.net'],\n",
              " ['android'],\n",
              " [],\n",
              " ['asp.net'],\n",
              " ['javascript', 'jquery'],\n",
              " ['ruby-on-rails', 'ruby-on-rails-3'],\n",
              " ['iphone'],\n",
              " ['c#', 'asp.net'],\n",
              " ['c#', '.net'],\n",
              " [],\n",
              " ['php', 'arrays'],\n",
              " ['objective-c', 'xcode'],\n",
              " ['asp.net-mvc-3'],\n",
              " ['css'],\n",
              " ['android'],\n",
              " ['windows-7'],\n",
              " ['c#'],\n",
              " [],\n",
              " ['javascript'],\n",
              " ['c#'],\n",
              " ['java', 'osx'],\n",
              " [],\n",
              " [],\n",
              " ['python', 'database'],\n",
              " ['javascript', 'jquery'],\n",
              " [],\n",
              " ['c#', '.net'],\n",
              " ['javascript', 'ajax'],\n",
              " [],\n",
              " [],\n",
              " ['android'],\n",
              " ['java', 'android'],\n",
              " [],\n",
              " ['jquery'],\n",
              " ['c#'],\n",
              " ['php', 'facebook'],\n",
              " ['ubuntu'],\n",
              " [],\n",
              " ['html5'],\n",
              " [],\n",
              " ['c#', '.net'],\n",
              " ['css'],\n",
              " ['wcf', 'security'],\n",
              " ['ruby-on-rails', 'ruby'],\n",
              " ['php', 'security'],\n",
              " ['jquery'],\n",
              " ['sql', 'sql-server'],\n",
              " ['java', 'windows'],\n",
              " ['c#', 'xml'],\n",
              " ['javascript', 'jquery'],\n",
              " ['iphone', 'ios'],\n",
              " ['linux'],\n",
              " ['html', 'css'],\n",
              " ['windows'],\n",
              " ['html'],\n",
              " ['php'],\n",
              " ['asp.net'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['c#'],\n",
              " [],\n",
              " ['c#', '.net'],\n",
              " ['iphone', 'objective-c'],\n",
              " [],\n",
              " ['vb.net'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['javascript'],\n",
              " ['asp.net'],\n",
              " [],\n",
              " [],\n",
              " ['wcf'],\n",
              " [],\n",
              " ['php'],\n",
              " ['wpf', 'vb.net'],\n",
              " [],\n",
              " ['html', 'css'],\n",
              " ['html', 'css'],\n",
              " ['jquery'],\n",
              " ['php'],\n",
              " ['c++'],\n",
              " ['c++'],\n",
              " [],\n",
              " ['java'],\n",
              " [],\n",
              " [],\n",
              " ['java', 'android', 'eclipse'],\n",
              " [],\n",
              " [],\n",
              " ['linux', 'ubuntu'],\n",
              " [],\n",
              " ['c#'],\n",
              " ['c++'],\n",
              " ['windows'],\n",
              " ['java', 'android'],\n",
              " [],\n",
              " ['c++', 'string'],\n",
              " [],\n",
              " ['java'],\n",
              " ['php'],\n",
              " ['java', 'android'],\n",
              " ['wcf'],\n",
              " ['php'],\n",
              " ['c'],\n",
              " ['android', 'facebook'],\n",
              " ['c#', 'asp.net', 'json'],\n",
              " ['html'],\n",
              " ['java'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['python'],\n",
              " [],\n",
              " ['ios'],\n",
              " [],\n",
              " ['php', 'facebook'],\n",
              " [],\n",
              " [],\n",
              " ['asp.net', 'vb.net'],\n",
              " ['javascript', 'jquery'],\n",
              " ['iphone'],\n",
              " ['html', 'css', 'html5'],\n",
              " ['javascript'],\n",
              " ['python', 'django'],\n",
              " ['java'],\n",
              " ['eclipse'],\n",
              " ['jquery'],\n",
              " [],\n",
              " ['osx'],\n",
              " ['visual-studio-2010'],\n",
              " ['php'],\n",
              " ['linux'],\n",
              " [],\n",
              " ['jquery'],\n",
              " [],\n",
              " [],\n",
              " ['javascript', 'jquery', 'ajax'],\n",
              " [],\n",
              " [],\n",
              " ['asp.net', 'asp.net-mvc'],\n",
              " ['java', 'c++'],\n",
              " [],\n",
              " ['iphone'],\n",
              " [],\n",
              " ['android'],\n",
              " [],\n",
              " [],\n",
              " ['c++', 'linux', 'performance'],\n",
              " ['jquery', 'asp.net-mvc-3'],\n",
              " [],\n",
              " [],\n",
              " ['c++', 'arrays'],\n",
              " [],\n",
              " ['vb.net'],\n",
              " ['c#'],\n",
              " ['wcf'],\n",
              " [],\n",
              " ['android'],\n",
              " ['c++', 'string'],\n",
              " ['xml'],\n",
              " ['ruby', 'regex'],\n",
              " ['android'],\n",
              " ['javascript'],\n",
              " ['html', 'ios', 'css'],\n",
              " [],\n",
              " [],\n",
              " ['java'],\n",
              " [],\n",
              " ['java', 'android'],\n",
              " ['ios'],\n",
              " ['osx'],\n",
              " ['xcode', 'osx'],\n",
              " ['sql-server', 'performance'],\n",
              " ['java'],\n",
              " ['python'],\n",
              " ['javascript', 'jquery', 'json'],\n",
              " ['windows'],\n",
              " ['security'],\n",
              " ['javascript'],\n",
              " ['asp.net'],\n",
              " ['ios'],\n",
              " [],\n",
              " [],\n",
              " ['javascript', 'html'],\n",
              " ['windows', 'linux'],\n",
              " [],\n",
              " ['iphone', 'css'],\n",
              " ['android'],\n",
              " ['c#', '.net'],\n",
              " ['javascript'],\n",
              " [],\n",
              " ['javascript'],\n",
              " ['c#', 'json'],\n",
              " ['.net', 'wpf'],\n",
              " ['ubuntu', 'python'],\n",
              " [],\n",
              " ['java', 'eclipse'],\n",
              " ['sql-server'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['asp.net', 'asp.net-mvc'],\n",
              " ['c++', 'ios', 'xcode'],\n",
              " ['python'],\n",
              " ['android'],\n",
              " [],\n",
              " ['python', 'json'],\n",
              " ['sql', 'sql-server'],\n",
              " ['asp.net'],\n",
              " [],\n",
              " [],\n",
              " ['sql-server'],\n",
              " ['c#', 'asp.net'],\n",
              " ['linux', 'security'],\n",
              " ['php'],\n",
              " ['wcf', 'security'],\n",
              " ['javascript', 'jquery', 'html'],\n",
              " [],\n",
              " [],\n",
              " ['cocoa'],\n",
              " [],\n",
              " ['php', 'regex', 'string'],\n",
              " [],\n",
              " ['c#', '.net'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['c#'],\n",
              " ['javascript', 'jquery'],\n",
              " ['html', 'css'],\n",
              " ['iphone', 'ios'],\n",
              " ['asp.net'],\n",
              " ['objective-c'],\n",
              " ['php', 'string'],\n",
              " ['c'],\n",
              " [],\n",
              " [],\n",
              " ['android'],\n",
              " ['windows'],\n",
              " ['jquery'],\n",
              " ['c'],\n",
              " ['sql-server'],\n",
              " ['java'],\n",
              " ['php', 'mysql'],\n",
              " ['iphone', 'objective-c', 'ios'],\n",
              " ['c#', 'java'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['java'],\n",
              " [],\n",
              " ['facebook'],\n",
              " ['mysql'],\n",
              " [],\n",
              " [],\n",
              " ['c#'],\n",
              " ['iphone', 'objective-c', 'xcode'],\n",
              " ['c++'],\n",
              " ['python'],\n",
              " ['android', 'eclipse'],\n",
              " ['security'],\n",
              " ['sql-server'],\n",
              " ['css'],\n",
              " [],\n",
              " ['php', 'html', 'regex'],\n",
              " [],\n",
              " [],\n",
              " ['javascript', 'html', 'css'],\n",
              " ['sql'],\n",
              " ['iphone'],\n",
              " ['javascript', 'jquery', 'html', 'css'],\n",
              " ['ios'],\n",
              " [],\n",
              " ['multithreading'],\n",
              " [],\n",
              " ['html', 'asp.net-mvc-3'],\n",
              " ['c#', '.net', 'wpf'],\n",
              " ['java'],\n",
              " [],\n",
              " ['python', 'django'],\n",
              " ['ruby-on-rails'],\n",
              " [],\n",
              " ['c#'],\n",
              " ['c#', 'asp.net', 'asp.net-mvc-3'],\n",
              " ['c++', 'windows'],\n",
              " ['java'],\n",
              " [],\n",
              " ['.net'],\n",
              " [],\n",
              " ['ruby-on-rails'],\n",
              " ['jquery'],\n",
              " ['jquery'],\n",
              " [],\n",
              " [],\n",
              " ['xcode'],\n",
              " ['eclipse'],\n",
              " [],\n",
              " ['javascript', 'jquery'],\n",
              " ['c++'],\n",
              " [],\n",
              " ['iphone', 'ios'],\n",
              " ['php'],\n",
              " ['javascript'],\n",
              " ['php', 'arrays'],\n",
              " [],\n",
              " ['windows'],\n",
              " ['javascript', 'css'],\n",
              " ['c#', 'android'],\n",
              " ['python'],\n",
              " [],\n",
              " [],\n",
              " ['java', 'multithreading'],\n",
              " [],\n",
              " ['sql'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['android'],\n",
              " ['c'],\n",
              " ['python'],\n",
              " [],\n",
              " ['ruby-on-rails'],\n",
              " [],\n",
              " ['c'],\n",
              " ['asp.net'],\n",
              " ['java'],\n",
              " ['javascript', 'asp.net'],\n",
              " ['iphone'],\n",
              " ['php'],\n",
              " ['java'],\n",
              " ['ruby-on-rails'],\n",
              " [],\n",
              " [],\n",
              " ['php', 'mysql'],\n",
              " ['ruby-on-rails'],\n",
              " ['javascript'],\n",
              " ['ruby-on-rails', 'database'],\n",
              " ['windows', 'string'],\n",
              " [],\n",
              " ['ruby-on-rails'],\n",
              " ['javascript'],\n",
              " [],\n",
              " ['c++'],\n",
              " ['cocoa'],\n",
              " ['database'],\n",
              " ['java', 'javascript'],\n",
              " ['javascript', 'jquery'],\n",
              " ['java'],\n",
              " ['c#', 'asp.net', 'vb.net'],\n",
              " ['java'],\n",
              " ['xcode', 'osx'],\n",
              " ['c++'],\n",
              " [],\n",
              " ['javascript'],\n",
              " ['javascript', 'jquery'],\n",
              " ['facebook'],\n",
              " ['python'],\n",
              " [],\n",
              " ['javascript', 'jquery'],\n",
              " [],\n",
              " [],\n",
              " ['jquery'],\n",
              " [],\n",
              " ['c++'],\n",
              " ['mysql'],\n",
              " ['java', 'android'],\n",
              " ['php'],\n",
              " [],\n",
              " [],\n",
              " ['html', 'css'],\n",
              " [],\n",
              " ['javascript'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['c#', '.net'],\n",
              " ['java', 'xml'],\n",
              " ['java', 'xml'],\n",
              " [],\n",
              " ['php', 'mysql', 'html'],\n",
              " [],\n",
              " [],\n",
              " ['php'],\n",
              " ['java'],\n",
              " ['mysql', 'database'],\n",
              " ['asp.net'],\n",
              " ['objective-c', 'xcode'],\n",
              " ['javascript', 'html'],\n",
              " ['java'],\n",
              " [],\n",
              " [],\n",
              " ['ruby'],\n",
              " [],\n",
              " [],\n",
              " ['c'],\n",
              " ['asp.net'],\n",
              " [],\n",
              " ['android', 'python'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['android'],\n",
              " ['asp.net'],\n",
              " [],\n",
              " ['linux'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['php', 'database'],\n",
              " [],\n",
              " ['css'],\n",
              " [],\n",
              " ['python'],\n",
              " ['php'],\n",
              " ['javascript', 'json'],\n",
              " ['ruby-on-rails', 'ruby-on-rails-3'],\n",
              " ['c#', 'asp.net', 'wcf'],\n",
              " ['java', 'regex'],\n",
              " ['asp.net'],\n",
              " ['asp.net-mvc-3'],\n",
              " ['javascript', 'asp.net'],\n",
              " ['ruby-on-rails'],\n",
              " [],\n",
              " ['sql', 'sql-server'],\n",
              " ['android', 'database'],\n",
              " ['php'],\n",
              " ['c#'],\n",
              " ['c#', 'visual-studio-2010'],\n",
              " [],\n",
              " ['css', 'facebook'],\n",
              " ['java'],\n",
              " [],\n",
              " [],\n",
              " ['php'],\n",
              " ['string'],\n",
              " ['objective-c', 'xcode'],\n",
              " [],\n",
              " [],\n",
              " ['performance'],\n",
              " ['php'],\n",
              " ['performance'],\n",
              " ['java'],\n",
              " ['c#'],\n",
              " ['java'],\n",
              " ['c#'],\n",
              " [],\n",
              " ['php', 'string'],\n",
              " ['jquery', 'ajax'],\n",
              " ['c#', '.net'],\n",
              " ['c#', '.net'],\n",
              " ['c'],\n",
              " ['php', 'mysql'],\n",
              " [],\n",
              " ['mysql'],\n",
              " ['iphone'],\n",
              " ['.net'],\n",
              " [],\n",
              " ['jquery'],\n",
              " ['ruby'],\n",
              " ['ios', 'regex'],\n",
              " ['android'],\n",
              " [],\n",
              " ['eclipse'],\n",
              " [],\n",
              " [],\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUArYb2Dw6ut",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6c56506-f1eb-40d9-9698-b01d94028c04"
      },
      "source": [
        "#One hot encode the ground truth data  TRAIN\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "train_tag_encoder = MultiLabelBinarizer()\n",
        "train_tags_encoded = train_tag_encoder.fit_transform(train_final_tag_data)\n",
        "train_tags_encoded.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd1rft_TyU7s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "161976bb-72cd-4527-f2fb-8bb551170b6c"
      },
      "source": [
        "train_tags_encoded[1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbaDou6_w6if",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fffe64a3-1804-4b00-f9f0-ed23499c7773"
      },
      "source": [
        "#One hot encode the ground truth data  Test\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "test_tag_encoder = MultiLabelBinarizer()\n",
        "test_tags_encoded = test_tag_encoder.fit_transform(test_final_tag_data)\n",
        "test_tags_encoded.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk--wj4AntmP"
      },
      "source": [
        "ID = 'Id'\n",
        "DATA_COLUMN = 'Title'\n",
        "LABEL_COLUMNS = 'Tags'\n",
        "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
        "# Define\n",
        "# train_label_list = train_final_tags #[0, 1]\n",
        "# test_label_list = test_final_tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YGuZW06m2Qf"
      },
      "source": [
        "# ID = 'Id'\n",
        "# DATA_COLUMN = 'Title'\n",
        "# LABEL_COLUMNS = ['Tags']\n",
        "# #['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTF_a0bvm2Qm"
      },
      "source": [
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, labels=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "            labels: (Optional) [string]. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_ids, is_real_example=True):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_ids = label_ids,\n",
        "        self.is_real_example=is_real_example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISFtaUveN32U"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJzs55-8m2Qr"
      },
      "source": [
        "def create_examples(df, labels_available=True):\n",
        "    \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "    examples = []\n",
        "    for (i, row) in enumerate(df.values): \n",
        "        guid = None\n",
        "        text_a = row[1]\n",
        "        if labels_available:\n",
        "            labels = train_tags_encoded[i] #row[2:]\n",
        "        else:\n",
        "            labels = [0]*50   #,0,0,0,0,0]\n",
        "        examples.append(\n",
        "            InputExample(guid=guid, text_a=text_a, labels=labels))\n",
        "    return examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58MBu0ozm2Qw"
      },
      "source": [
        "TRAIN_VAL_RATIO = 0.9\n",
        "LEN = train.shape[0]\n",
        "SIZE_TRAIN = int(TRAIN_VAL_RATIO*LEN)\n",
        "\n",
        "x_train = train[:SIZE_TRAIN]\n",
        "x_val = train[SIZE_TRAIN:]\n",
        "\n",
        "train_examples = create_examples(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eAa0zaTm2Q1"
      },
      "source": [
        "def convert_examples_to_features(examples,  max_seq_length, tokenizer):\n",
        "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        print(example.text_a)\n",
        "        tokens_a = tokenizer.tokenize(example.text_a)\n",
        "\n",
        "        tokens_b = None\n",
        "        if example.text_b:\n",
        "            tokens_b = tokenizer.tokenize(example.text_b)\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "            # length is less than the specified length.\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "        else:\n",
        "            # Account for [CLS] and [SEP] with \"- 2\"\n",
        "            if len(tokens_a) > max_seq_length - 2:\n",
        "                tokens_a = tokens_a[:(max_seq_length - 2)]\n",
        "\n",
        "        # The convention in BERT is:\n",
        "        # (a) For sequence pairs:\n",
        "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
        "        # (b) For single sequences:\n",
        "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "        #  type_ids: 0   0   0   0  0     0 0\n",
        "        #\n",
        "        # Where \"type_ids\" are used to indicate whether this is the first\n",
        "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "        # embedding vector (and position vector). This is not *strictly* necessary\n",
        "        # since the [SEP] token unambigiously separates the sequences, but it makes\n",
        "        # it easier for the model to learn the concept of sequences.\n",
        "        #\n",
        "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "        # the entire model is fine-tuned.\n",
        "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
        "        segment_ids = [0] * len(tokens)\n",
        "\n",
        "        if tokens_b:\n",
        "            tokens += tokens_b + [\"[SEP]\"]\n",
        "            segment_ids += [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding = [0] * (max_seq_length - len(input_ids))\n",
        "        input_ids += padding\n",
        "        input_mask += padding\n",
        "        segment_ids += padding\n",
        "\n",
        "        assert len(input_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "        \n",
        "        labels_ids = []\n",
        "        for label in example.labels:\n",
        "            labels_ids.append(int(label))\n",
        "\n",
        "        if ex_index < 0:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            #logger.info(\"guid: %s\" % (example.guid))\n",
        "            logger.info(\"tokens: %s\" % \" \".join(\n",
        "                    [str(x) for x in tokens]))\n",
        "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "            logger.info(\n",
        "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
        "            logger.info(\"label: %s (id = %s)\" % (example.labels, labels_ids))\n",
        "\n",
        "        features.append(\n",
        "                InputFeatures(input_ids=input_ids,\n",
        "                              input_mask=input_mask,\n",
        "                              segment_ids=segment_ids,\n",
        "                              label_ids=labels_ids))\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cup_e2lIm2Q5"
      },
      "source": [
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBJPCH3Ym2Q8"
      },
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 1.0\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 1000\n",
        "SAVE_SUMMARY_STEPS = 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnt0HGV_m2Q-"
      },
      "source": [
        "class PaddingInputExample(object):\n",
        "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
        "    When running eval/predict on the TPU, we need to pad the number of examples\n",
        "    to be a multiple of the batch size, because the TPU requires a fixed batch\n",
        "    size. The alternative is to drop the last batch, which is bad because it means\n",
        "    the entire output data won't be generated.\n",
        "    We use this class instead of `None` because treating `None` as padding\n",
        "    battches could cause silent errors.\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "def convert_single_example(ex_index, example, max_seq_length,\n",
        "                           tokenizer):\n",
        "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
        "\n",
        "    if isinstance(example, PaddingInputExample):\n",
        "        return InputFeatures(\n",
        "            input_ids=[0] * max_seq_length,\n",
        "            input_mask=[0] * max_seq_length,\n",
        "            segment_ids=[0] * max_seq_length,\n",
        "            label_ids=0,\n",
        "            is_real_example=False)\n",
        "\n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "    tokens_b = None\n",
        "    if example.text_b:\n",
        "        tokens_b = tokenizer.tokenize(example.text_b)\n",
        "\n",
        "    if tokens_b:\n",
        "        # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "        # length is less than the specified length.\n",
        "        # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "    else:\n",
        "        # Account for [CLS] and [SEP] with \"- 2\"\n",
        "        if len(tokens_a) > max_seq_length - 2:\n",
        "            tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "\n",
        "    # The convention in BERT is:\n",
        "    # (a) For sequence pairs:\n",
        "    #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "    #  type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
        "    # (b) For single sequences:\n",
        "    #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "    #  type_ids: 0     0   0   0  0     0 0\n",
        "    #\n",
        "    # Where \"type_ids\" are used to indicate whether this is the first\n",
        "    # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "    # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "    # embedding vector (and position vector). This is not *strictly* necessary\n",
        "    # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "    # it easier for the model to learn the concept of sequences.\n",
        "    #\n",
        "    # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "    # used as the \"sentence vector\". Note that this only makes sense because\n",
        "    # the entire model is fine-tuned.\n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    tokens.append(\"[CLS]\")\n",
        "    segment_ids.append(0)\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(0)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    segment_ids.append(0)\n",
        "\n",
        "    if tokens_b:\n",
        "        for token in tokens_b:\n",
        "            tokens.append(token)\n",
        "            segment_ids.append(1)\n",
        "        tokens.append(\"[SEP]\")\n",
        "        segment_ids.append(1)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    while len(input_ids) < max_seq_length:\n",
        "        input_ids.append(0)\n",
        "        input_mask.append(0)\n",
        "        segment_ids.append(0)\n",
        "\n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "\n",
        "    labels_ids = []\n",
        "    for label in example.labels:\n",
        "        labels_ids.append(int(label))\n",
        "\n",
        "\n",
        "    feature = InputFeatures(\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        segment_ids=segment_ids,\n",
        "        label_ids=labels_ids,\n",
        "        is_real_example=True)\n",
        "    return feature\n",
        "\n",
        "\n",
        "def file_based_convert_examples_to_features(\n",
        "        examples, max_seq_length, tokenizer, output_file):\n",
        "    \"\"\"Convert a set of `InputExample`s to a TFRecord file.\"\"\"\n",
        "\n",
        "    writer = tf.python_io.TFRecordWriter(output_file)\n",
        "\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        #if ex_index % 10000 == 0:\n",
        "            #tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
        "\n",
        "        feature = convert_single_example(ex_index, example,\n",
        "                                         max_seq_length, tokenizer)\n",
        "\n",
        "        def create_int_feature(values):\n",
        "            f = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n",
        "            return f\n",
        "\n",
        "        features = collections.OrderedDict()\n",
        "        features[\"input_ids\"] = create_int_feature(feature.input_ids)\n",
        "        features[\"input_mask\"] = create_int_feature(feature.input_mask)\n",
        "        features[\"segment_ids\"] = create_int_feature(feature.segment_ids)\n",
        "        features[\"is_real_example\"] = create_int_feature(\n",
        "            [int(feature.is_real_example)])\n",
        "        if isinstance(feature.label_ids, list):\n",
        "            label_ids = feature.label_ids\n",
        "        else:\n",
        "            label_ids = feature.label_ids[0]\n",
        "        features[\"label_ids\"] = create_int_feature(label_ids)\n",
        "\n",
        "        tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "def file_based_input_fn_builder(input_file, seq_length, is_training,\n",
        "                                drop_remainder):\n",
        "    \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "    name_to_features = {\n",
        "        \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "        \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "        \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "        \"label_ids\": tf.FixedLenFeature([50], tf.int64),   # I CHANGED INITALY = [6]\n",
        "        \"is_real_example\": tf.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "\n",
        "    def _decode_record(record, name_to_features):\n",
        "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
        "        example = tf.parse_single_example(record, name_to_features)\n",
        "\n",
        "        # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
        "        # So cast all int64 to int32.\n",
        "        for name in list(example.keys()):\n",
        "            t = example[name]\n",
        "            if t.dtype == tf.int64:\n",
        "                t = tf.to_int32(t)\n",
        "            example[name] = t\n",
        "\n",
        "        return example\n",
        "\n",
        "    def input_fn(params):\n",
        "        \"\"\"The actual input function.\"\"\"\n",
        "        batch_size = params[\"batch_size\"]\n",
        "\n",
        "        # For training, we want a lot of parallel reading and shuffling.\n",
        "        # For eval, we want no shuffling and parallel reading doesn't matter.\n",
        "        d = tf.data.TFRecordDataset(input_file)\n",
        "        if is_training:\n",
        "            d = d.repeat()\n",
        "            d = d.shuffle(buffer_size=100)\n",
        "\n",
        "        d = d.apply(\n",
        "            tf.contrib.data.map_and_batch(\n",
        "                lambda record: _decode_record(record, name_to_features),\n",
        "                batch_size=batch_size,\n",
        "                drop_remainder=drop_remainder))\n",
        "\n",
        "        return d\n",
        "\n",
        "    return input_fn\n",
        "\n",
        "\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAAs5HB4m2RA"
      },
      "source": [
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_examples) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAk5SVCem2RD"
      },
      "source": [
        "train_file = os.path.join('/content/drive/My Drive/BERT_OUTPUT', \"train.tf_record\")\n",
        "#filename = Path(train_file)\n",
        "if not os.path.exists(train_file):\n",
        "    open(train_file, 'w').close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNDzuVYgm2RF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "91bf5c63-5638-4b27-e7d1-9faa0273adbb"
      },
      "source": [
        "file_based_convert_examples_to_features(\n",
        "            train_examples, MAX_SEQ_LENGTH, tokenizer, train_file)\n",
        "tf.logging.info(\"***** Running training *****\")\n",
        "tf.logging.info(\"  Num examples = %d\", len(train_examples))\n",
        "tf.logging.info(\"  Batch size = %d\", BATCH_SIZE)\n",
        "tf.logging.info(\"  Num steps = %d\", num_train_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:***** Running training *****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:***** Running training *****\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  Num examples = 4500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  Num examples = 4500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  Batch size = 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  Batch size = 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  Num steps = 140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  Num steps = 140\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akBEfHpRm2RI"
      },
      "source": [
        "train_input_fn = file_based_input_fn_builder(\n",
        "    input_file=train_file,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xljJdKOVm2RL"
      },
      "source": [
        "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "                 labels, num_labels, use_one_hot_embeddings):\n",
        "    \"\"\"Creates a classification model.\"\"\"\n",
        "    model = modeling.BertModel(\n",
        "        config=bert_config,\n",
        "        is_training=is_training,\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        token_type_ids=segment_ids,\n",
        "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "    # In the demo, we are doing a simple classification task on the entire\n",
        "    # segment.\n",
        "    #\n",
        "    # If you want to use the token-level output, use model.get_sequence_output()\n",
        "    # instead.\n",
        "    output_layer = model.get_pooled_output()\n",
        "\n",
        "    hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "    output_weights = tf.get_variable(\n",
        "        \"output_weights\", [num_labels, hidden_size],\n",
        "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "    output_bias = tf.get_variable(\n",
        "        \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "    with tf.variable_scope(\"loss\"):\n",
        "        if is_training:\n",
        "            # I.e., 0.1 dropout\n",
        "            output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "        logits = tf.nn.bias_add(logits, output_bias)\n",
        "        \n",
        "        # probabilities = tf.nn.softmax(logits, axis=-1) ### multiclass case\n",
        "        probabilities = tf.nn.sigmoid(logits)#### multi-label case\n",
        "        \n",
        "        #I ADDED INITIALLY ONE_HOT\n",
        "        #labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "        labels = tf.cast(labels, tf.float32)\n",
        "        tf.logging.info(\"num_labels:{};logits:{};labels:{}\".format(num_labels, logits, labels))\n",
        "        per_example_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n",
        "        loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "        # probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "        # log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "        #\n",
        "        #one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "        #\n",
        "        # per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "        # loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "        return (loss, per_example_loss, logits, probabilities)\n",
        "\n",
        "\n",
        "def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,\n",
        "                     num_train_steps, num_warmup_steps, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "        #tf.logging.info(\"*** Features ***\")\n",
        "        #for name in sorted(features.keys()):\n",
        "        #    tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "        input_ids = features[\"input_ids\"]\n",
        "        input_mask = features[\"input_mask\"]\n",
        "        segment_ids = features[\"segment_ids\"]\n",
        "        label_ids = features[\"label_ids\"]\n",
        "        is_real_example = None\n",
        "        if \"is_real_example\" in features:\n",
        "             is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
        "        else:\n",
        "             is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
        "\n",
        "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "        (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
        "            bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
        "            num_labels, use_one_hot_embeddings)\n",
        "\n",
        "        tvars = tf.trainable_variables()\n",
        "        initialized_variable_names = {}\n",
        "        scaffold_fn = None\n",
        "        if init_checkpoint:\n",
        "            (assignment_map, initialized_variable_names\n",
        "             ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "            if use_tpu:\n",
        "\n",
        "                def tpu_scaffold():\n",
        "                    tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "                    return tf.train.Scaffold()\n",
        "\n",
        "                scaffold_fn = tpu_scaffold\n",
        "            else:\n",
        "                tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "        tf.logging.info(\"**** Trainable Variables ****\")\n",
        "        for var in tvars:\n",
        "            init_string = \"\"\n",
        "            if var.name in initialized_variable_names:\n",
        "                init_string = \", *INIT_FROM_CKPT*\"\n",
        "            #tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,init_string)\n",
        "\n",
        "        output_spec = None\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "\n",
        "            train_op = optimization.create_optimizer(\n",
        "                total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "\n",
        "            output_spec = tf.estimator.EstimatorSpec(\n",
        "                mode=mode,\n",
        "                loss=total_loss,\n",
        "                train_op=train_op,\n",
        "                scaffold=scaffold_fn)\n",
        "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "\n",
        "            def metric_fn(per_example_loss, label_ids, probabilities, is_real_example):\n",
        "\n",
        "                logits_split = tf.split(probabilities, num_labels, axis=-1)\n",
        "                label_ids_split = tf.split(label_ids, num_labels, axis=-1)\n",
        "                # metrics change to auc of every class\n",
        "                eval_dict = {}\n",
        "                for j, logits in enumerate(logits_split):\n",
        "                    label_id_ = tf.cast(label_ids_split[j], dtype=tf.int32)\n",
        "                    current_auc, update_op_auc = tf.metrics.auc(label_id_, logits)\n",
        "                    eval_dict[str(j)] = (current_auc, update_op_auc)\n",
        "                eval_dict['eval_loss'] = tf.metrics.mean(values=per_example_loss)\n",
        "                return eval_dict\n",
        "\n",
        "                ## original eval metrics\n",
        "                # predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "                # accuracy = tf.metrics.accuracy(\n",
        "                #     labels=label_ids, predictions=predictions, weights=is_real_example)\n",
        "                # loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
        "                # return {\n",
        "                #     \"eval_accuracy\": accuracy,\n",
        "                #     \"eval_loss\": loss,\n",
        "                # }\n",
        "\n",
        "            eval_metrics = metric_fn(per_example_loss, label_ids, probabilities, is_real_example)\n",
        "            output_spec = tf.estimator.EstimatorSpec(\n",
        "                mode=mode,\n",
        "                loss=total_loss,\n",
        "                eval_metric_ops=eval_metrics,\n",
        "                scaffold=scaffold_fn)\n",
        "        else:\n",
        "            print(\"mode:\", mode,\"probabilities:\", probabilities)\n",
        "            output_spec = tf.estimator.EstimatorSpec(\n",
        "                mode=mode,\n",
        "                predictions={\"probabilities\": probabilities},\n",
        "                scaffold=scaffold_fn)\n",
        "        return output_spec\n",
        "\n",
        "    return model_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8Cr2tfjm2RO"
      },
      "source": [
        "OUTPUT_DIR = \"/content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT\"\n",
        "# Specify outpit directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    keep_checkpoint_max=1,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U_9Pzklm2RQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "0b35eef1-71d0-4988-b30f-33d0c12d9c37"
      },
      "source": [
        "bert_config = modeling.BertConfig.from_json_file(BERT_CONFIG)\n",
        "model_fn = model_fn_builder(\n",
        "  bert_config=bert_config,\n",
        "  num_labels= 50, #len(LABEL_COLUMNS),\n",
        "  init_checkpoint=BERT_INIT_CHKPNT,\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps,\n",
        "  use_tpu=False,\n",
        "  use_one_hot_embeddings=False)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0953287cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0953287cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dMfvQvlm2RT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69ab19d4-b165-4adf-f811-6e620358a1bf"
      },
      "source": [
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-28-90e77a1045ff>:179: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-28-90e77a1045ff>:179: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-28-90e77a1045ff>:159: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-28-90e77a1045ff>:159: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_labels:50;logits:Tensor(\"loss/BiasAdd:0\", shape=(32, 50), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(32, 50), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_labels:50;logits:Tensor(\"loss/BiasAdd:0\", shape=(32, 50), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(32, 50), dtype=float32)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:**** Trainable Variables ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:**** Trainable Variables ****\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt-0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt-0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.70500076, step = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.70500076, step = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0222757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0222757\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.09061712, step = 101 (4489.206 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.09061712, step = 101 (4489.206 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 110 vs previous value: 110. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 110 vs previous value: 110. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 112 vs previous value: 112. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 112 vs previous value: 112. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 115 vs previous value: 115. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 115 vs previous value: 115. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 117 vs previous value: 117. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 117 vs previous value: 117. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 119 vs previous value: 119. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 119 vs previous value: 119. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 140 into /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 140 into /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.09041238.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.09041238.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training took time  1:46:12.561647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdpLd9o5m2RW"
      },
      "source": [
        "eval_file = os.path.join('/content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT', \"eval.tf_record\")\n",
        "#filename = Path(train_file)\n",
        "if not os.path.exists(eval_file):\n",
        "    open(eval_file, 'w').close()\n",
        "\n",
        "eval_examples = create_examples(x_val)\n",
        "file_based_convert_examples_to_features(\n",
        "    eval_examples, MAX_SEQ_LENGTH, tokenizer, eval_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df0_0e4pm2RY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "8bed9c18-eab1-4eda-c87b-2c28e9dd1179"
      },
      "source": [
        "# This tells the estimator to run through the entire set.\n",
        "eval_steps = None\n",
        "\n",
        "eval_drop_remainder = False\n",
        "eval_input_fn = file_based_input_fn_builder(\n",
        "    input_file=eval_file,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)\n",
        "\n",
        "result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_labels:50;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 50), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 50), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_labels:50;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 50), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 50), dtype=float32)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:**** Trainable Variables ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:**** Trainable Variables ****\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-06-09T12:28:03Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-06-09T12:28:03Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt-140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt-140\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-06-09-12:32:01\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-06-09-12:32:01\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 140: 0 = 0.50000006, 1 = 0.50000024, 10 = 0.5, 11 = 0.50000006, 12 = 0.5000001, 13 = 1.0, 14 = 0.5000001, 15 = 0.50000006, 16 = 0.50000006, 17 = 0.5000002, 18 = 0.5000001, 19 = 0.5000002, 2 = 0.5, 20 = 0.50000006, 21 = 0.421194, 22 = 0.5000002, 23 = 0.3427421, 24 = 0.50000006, 25 = 0.5, 26 = 0.49438277, 27 = 0.5005681, 28 = 0.5, 29 = 0.572449, 3 = 0.50000024, 30 = 0.5000001, 31 = 0.50000006, 32 = 0.50000006, 33 = 0.50000006, 34 = 0.5000001, 35 = 0.5, 36 = 0.5072314, 37 = 0.50000024, 38 = 0.5000002, 39 = 0.5000001, 4 = 0.5964864, 40 = 0.50000006, 41 = 0.50000024, 42 = 0.5000002, 43 = 0.5000001, 44 = 0.50000006, 45 = 0.50000006, 46 = 0.50000024, 47 = 0.5000001, 48 = 0.5000002, 49 = 0.5000001, 5 = 0.5000001, 6 = 0.50000006, 7 = 0.5, 8 = 0.54868776, 9 = 0.5000005, eval_loss = 0.10431888, global_step = 140, loss = 0.10391107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 140: 0 = 0.50000006, 1 = 0.50000024, 10 = 0.5, 11 = 0.50000006, 12 = 0.5000001, 13 = 1.0, 14 = 0.5000001, 15 = 0.50000006, 16 = 0.50000006, 17 = 0.5000002, 18 = 0.5000001, 19 = 0.5000002, 2 = 0.5, 20 = 0.50000006, 21 = 0.421194, 22 = 0.5000002, 23 = 0.3427421, 24 = 0.50000006, 25 = 0.5, 26 = 0.49438277, 27 = 0.5005681, 28 = 0.5, 29 = 0.572449, 3 = 0.50000024, 30 = 0.5000001, 31 = 0.50000006, 32 = 0.50000006, 33 = 0.50000006, 34 = 0.5000001, 35 = 0.5, 36 = 0.5072314, 37 = 0.50000024, 38 = 0.5000002, 39 = 0.5000001, 4 = 0.5964864, 40 = 0.50000006, 41 = 0.50000024, 42 = 0.5000002, 43 = 0.5000001, 44 = 0.50000006, 45 = 0.50000006, 46 = 0.50000024, 47 = 0.5000001, 48 = 0.5000002, 49 = 0.5000001, 5 = 0.5000001, 6 = 0.50000006, 7 = 0.5, 8 = 0.54868776, 9 = 0.5000005, eval_loss = 0.10431888, global_step = 140, loss = 0.10391107\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 140: /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt-140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 140: /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt-140\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hBv7PRTm2Re",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "023926d7-8d53-4fe1-9bb9-1878200e13ed"
      },
      "source": [
        "output_eval_file = os.path.join('/content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT', \"eval_results.txt\")\n",
        "with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "    tf.logging.info(\"***** Eval results *****\")\n",
        "    for key in sorted(result.keys()):\n",
        "        tf.logging.info(\"  %s = %s\", key, str(result[key]))\n",
        "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:***** Eval results *****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:***** Eval results *****\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  0 = 0.50000006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  0 = 0.50000006\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  1 = 0.50000024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  1 = 0.50000024\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  10 = 0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  10 = 0.5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  11 = 0.50000006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  11 = 0.50000006\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  12 = 0.5000001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  12 = 0.5000001\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  13 = 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  13 = 1.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  14 = 0.5000001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  14 = 0.5000001\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  15 = 0.50000006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  15 = 0.50000006\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  16 = 0.50000006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  16 = 0.50000006\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  17 = 0.5000002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  17 = 0.5000002\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  18 = 0.5000001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  18 = 0.5000001\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  19 = 0.5000002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  19 = 0.5000002\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  2 = 0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  2 = 0.5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  20 = 0.50000006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  20 = 0.50000006\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  21 = 0.421194\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  21 = 0.421194\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  22 = 0.5000002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  22 = 0.5000002\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  23 = 0.3427421\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  23 = 0.3427421\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  24 = 0.50000006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  24 = 0.50000006\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  25 = 0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  25 = 0.5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  26 = 0.49438277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  26 = 0.49438277\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  27 = 0.5005681\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  27 = 0.5005681\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  28 = 0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  28 = 0.5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  29 = 0.572449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  29 = 0.572449\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  3 = 0.50000024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  3 = 0.50000024\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  30 = 0.5000001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  30 = 0.5000001\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  31 = 0.50000006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  31 = 0.50000006\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  32 = 0.50000006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  32 = 0.50000006\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  33 = 0.50000006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  33 = 0.50000006\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  34 = 0.5000001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  34 = 0.5000001\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  35 = 0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  35 = 0.5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  36 = 0.5072314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  36 = 0.5072314\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  37 = 0.50000024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  37 = 0.50000024\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  38 = 0.5000002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  38 = 0.5000002\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  39 = 0.5000001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  39 = 0.5000001\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  4 = 0.5964864\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  4 = 0.5964864\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  40 = 0.50000006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  40 = 0.50000006\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  41 = 0.50000024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  41 = 0.50000024\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  42 = 0.5000002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  42 = 0.5000002\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  43 = 0.5000001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  43 = 0.5000001\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  44 = 0.50000006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  44 = 0.50000006\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  45 = 0.50000006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  45 = 0.50000006\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  46 = 0.50000024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  46 = 0.50000024\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  47 = 0.5000001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  47 = 0.5000001\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  48 = 0.5000002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  48 = 0.5000002\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  49 = 0.5000001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  49 = 0.5000001\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  5 = 0.5000001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  5 = 0.5000001\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  6 = 0.50000006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  6 = 0.50000006\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  7 = 0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  7 = 0.5\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  8 = 0.54868776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  8 = 0.54868776\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  9 = 0.5000005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  9 = 0.5000005\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  eval_loss = 0.10431888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  eval_loss = 0.10431888\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  global_step = 140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  global_step = 140\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  loss = 0.10391107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:  loss = 0.10391107\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWCBf-QSm2Rg"
      },
      "source": [
        "x_test = test[:10] #testing a small sample\n",
        "x_test = x_test.reset_index(drop=True)\n",
        "predict_examples = create_examples(x_test,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ1vJk_-m2Ri",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "b6f07f79-81b7-4500-e697-d9367239d080"
      },
      "source": [
        "test_features = convert_examples_to_features(predict_examples, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "change default blue color in android holo theme to orange  or anything else \n",
            "django admin configuration\n",
            "how to solve the number of game frame decreased when we use particles   additive texture mapping \n",
            "layered architecture and static methods\n",
            "aligning to the bottom of an li \n",
            "adt plugin not showing up in eclipse indigo\n",
            "abstracting threading and multiprocessing in python \n",
            "implementing dijkstra is algorithm using min heap but failed\n",
            "call a shell script from another shell script via sudo   environment variables \n",
            "why can i not disable full range auto focus in newer point and shoot cameras \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYXHdG8lQWqF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "outputId": "697eb35a-0377-4645-8400-0bd6e83c2c27"
      },
      "source": [
        "x_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>489139</td>\n",
              "      <td>change default blue color in android holo them...</td>\n",
              "      <td>i am using holo theme in my app  style name  a...</td>\n",
              "      <td>[android, styles, themes]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3674823</td>\n",
              "      <td>django admin configuration</td>\n",
              "      <td>i have got a mental block on this one i have a...</td>\n",
              "      <td>[django, admin, models]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1692374</td>\n",
              "      <td>how to solve the number of game frame decrease...</td>\n",
              "      <td>the game engine unity3dthe number of game fram...</td>\n",
              "      <td>[frame, texture, unity3d, alpha, particles]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2081499</td>\n",
              "      <td>layered architecture and static methods</td>\n",
              "      <td>i need suggestion for three layered architectu...</td>\n",
              "      <td>[.net, layered]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>142316</td>\n",
              "      <td>aligning to the bottom of an li</td>\n",
              "      <td>i want to do this without javascript i can not...</td>\n",
              "      <td>[html, css, html-lists]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>54079</td>\n",
              "      <td>adt plugin not showing up in eclipse indigo</td>\n",
              "      <td>i have recently installed fedora 16 and i am t...</td>\n",
              "      <td>[eclipse, fedora, adt]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>82685</td>\n",
              "      <td>abstracting threading and multiprocessing in p...</td>\n",
              "      <td>is there a module that abstract threading and ...</td>\n",
              "      <td>[python]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1801021</td>\n",
              "      <td>implementing dijkstra is algorithm using min h...</td>\n",
              "      <td>i am trying to implement dijkstra is algorithm...</td>\n",
              "      <td>[java, algorithm, graph, shortest-path, dijkstra]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3609831</td>\n",
              "      <td>call a shell script from another shell script ...</td>\n",
              "      <td>i am calling bash script b from script a  in s...</td>\n",
              "      <td>[bash, shell, environment-variables, sudo]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3420966</td>\n",
              "      <td>why can i not disable full range auto focus in...</td>\n",
              "      <td>i owned a number of canon powershot cameras  s...</td>\n",
              "      <td>[autofocus, android, powershot]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id  ...                                               Tags\n",
              "0   489139  ...                          [android, styles, themes]\n",
              "1  3674823  ...                            [django, admin, models]\n",
              "2  1692374  ...        [frame, texture, unity3d, alpha, particles]\n",
              "3  2081499  ...                                    [.net, layered]\n",
              "4   142316  ...                            [html, css, html-lists]\n",
              "5    54079  ...                             [eclipse, fedora, adt]\n",
              "6    82685  ...                                           [python]\n",
              "7  1801021  ...  [java, algorithm, graph, shortest-path, dijkstra]\n",
              "8  3609831  ...         [bash, shell, environment-variables, sudo]\n",
              "9  3420966  ...                    [autofocus, android, powershot]\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc2uSGHJm2Rn"
      },
      "source": [
        "def input_fn_builder(features, seq_length, is_training, drop_remainder):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "  all_input_ids = []\n",
        "  all_input_mask = []\n",
        "  all_segment_ids = []\n",
        "  all_label_ids = []\n",
        "\n",
        "  for feature in features:\n",
        "    all_input_ids.append(feature.input_ids)\n",
        "    all_input_mask.append(feature.input_mask)\n",
        "    all_segment_ids.append(feature.segment_ids)\n",
        "    all_label_ids.append(feature.label_ids)\n",
        "\n",
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    batch_size = params[\"batch_size\"]\n",
        "\n",
        "    num_examples = len(features)\n",
        "\n",
        "    # This is for demo purposes and does NOT scale to large data sets. We do\n",
        "    # not use Dataset.from_generator() because that uses tf.py_func which is\n",
        "    # not TPU compatible. The right way to load data is with TFRecordReader.\n",
        "    d = tf.data.Dataset.from_tensor_slices({\n",
        "        \"input_ids\":\n",
        "            tf.constant(\n",
        "                all_input_ids, shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"input_mask\":\n",
        "            tf.constant(\n",
        "                all_input_mask,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"segment_ids\":\n",
        "            tf.constant(\n",
        "                all_segment_ids,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"label_ids\":\n",
        "            tf.constant(all_label_ids, shape=[num_examples, 50], dtype=tf.int32),\n",
        "    }) #len(LABEL_COLUMNS)\n",
        "\n",
        "    if is_training:\n",
        "      d = d.repeat()\n",
        "      d = d.shuffle(buffer_size=100)\n",
        "\n",
        "    d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
        "    return d\n",
        "\n",
        "  return input_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGkqb9rym2Rq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "42217e5d-8fc0-4b18-c2b2-a7e1ce496773"
      },
      "source": [
        "print('Beginning Predictions!')\n",
        "current_time = datetime.now()\n",
        "\n",
        "predict_input_fn = input_fn_builder(features=test_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "predictions = estimator.predict(predict_input_fn)\n",
        "print(predictions)\n",
        "print(\"Prediction took time \", datetime.now() - current_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Predictions!\n",
            "<generator object Estimator.predict at 0x7f094b70afc0>\n",
            "Prediction took time  0:00:00.000183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-F2nFHwkkl6"
      },
      "source": [
        "# for i,value in enumerate(predictions):\n",
        "#   print(i, value)\n",
        "#         if value > 0.5:\n",
        "#             predictions[i] = 1\n",
        "#         else:\n",
        "#             predictions[i] = 0\n",
        "# tags = test_tag_encoder.inverse_transform(np.array([predictions]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5Ew_JARm2Rt"
      },
      "source": [
        "def create_output(predictions):\n",
        "    probabilities = []\n",
        "    for (i, prediction) in enumerate(predictions):\n",
        "        preds = prediction['probabilities']\n",
        "        probabilities.append(preds)\n",
        "        #print(probabilities)\n",
        "    dff = pd.DataFrame(probabilities)\n",
        "    dff.columns = LABEL_COLUMNS\n",
        "    \n",
        "    return dff\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEgbzUrTm2Ru",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "outputId": "7cea1f74-aa19-4acf-d5cc-e7a0f21f2d16"
      },
      "source": [
        "output_df = create_output(predictions)\n",
        "merged_df =  pd.concat([x_test, output_df], axis=1)\n",
        "submission = merged_df.drop(['comment_text'], axis=1)\n",
        "submission.to_csv(\"sample_submission0.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_labels:50;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 50), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 50), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_labels:50;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 50), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 50), dtype=float32)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:**** Trainable Variables ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:**** Trainable Variables ****\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mode: infer probabilities: Tensor(\"loss/Sigmoid:0\", shape=(?, 50), dtype=float32)\n",
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt-140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt-140\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-4b516ff1bf02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sample_submission0.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-103-154a9f3e91ce>\u001b[0m in \u001b[0;36mcreate_output\u001b[0;34m(predictions)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#print(probabilities)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLABEL_COLUMNS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5287\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5288\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5289\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mold_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mnew_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   5356\u001b[0m             \u001b[0mindex_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5358\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scalar_data_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtupleize_cols\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Index(...) must be called with a collection of some kind, 'Tags' was passed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVavkxMgIKa-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd2945f5-65b5-4b9e-ba06-db9656069caa"
      },
      "source": [
        "# def gen_pre(predictions):\n",
        "#     probabilities = []\n",
        "#     for (i, prediction) in enumerate(predictions):\n",
        "#         preds = prediction[\"probabilities\"]\n",
        "#         probabilities.append(preds)\n",
        "#     return probabilities\n",
        "  # if prediction > 0.5:\n",
        "  #   prediction[i] = 1\n",
        "  # else:\n",
        "\n",
        "\n",
        "  # preds = prediction['probabilities']\n",
        "  #       probabilities.append(preds)\n",
        "  #       #print(probabilities)\n",
        "\n",
        "[(sentence, prediction['probabilities']) for sentence, prediction in zip(predict_examples, predictions)]\n",
        "# [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(predict_examples, predictions)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_labels:50;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 50), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 50), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_labels:50;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 50), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 50), dtype=float32)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:**** Trainable Variables ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:**** Trainable Variables ****\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mode: infer probabilities: Tensor(\"loss/Sigmoid:0\", shape=(?, 50), dtype=float32)\n",
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt-140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt-140\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(<__main__.InputExample at 0x7f094c8c0ac8>,\n",
              "  array([0.03849465, 0.043286  , 0.05634689, 0.04405656, 0.05000308,\n",
              "         0.04735276, 0.04797074, 0.08364806, 0.07622784, 0.04169148,\n",
              "         0.04468185, 0.040815  , 0.04693601, 0.05220434, 0.02790022,\n",
              "         0.03910238, 0.03657055, 0.02973711, 0.04648602, 0.04144642,\n",
              "         0.05322158, 0.03510898, 0.03664082, 0.03549328, 0.02820802,\n",
              "         0.04911071, 0.08529949, 0.07061601, 0.06504124, 0.05092382,\n",
              "         0.04241371, 0.04792306, 0.05002648, 0.04215783, 0.03733307,\n",
              "         0.06657854, 0.05548838, 0.03897947, 0.05050904, 0.05327958,\n",
              "         0.05452967, 0.04366428, 0.03993604, 0.04300839, 0.03615299,\n",
              "         0.03369543, 0.04068395, 0.04164919, 0.03947237, 0.04613531],\n",
              "        dtype=float32)),\n",
              " (<__main__.InputExample at 0x7f094c8c0588>,\n",
              "  array([0.0388217 , 0.04318565, 0.05599087, 0.04400915, 0.05007738,\n",
              "         0.0470888 , 0.04803234, 0.0834398 , 0.07556733, 0.04181683,\n",
              "         0.04466367, 0.04114768, 0.04675978, 0.05241653, 0.02825662,\n",
              "         0.03934273, 0.03641534, 0.02932075, 0.04669452, 0.04164705,\n",
              "         0.05336413, 0.03541696, 0.03658918, 0.03520069, 0.02824733,\n",
              "         0.04879171, 0.08487263, 0.07089114, 0.06453282, 0.05023894,\n",
              "         0.04234591, 0.04780668, 0.04960498, 0.04216135, 0.03725734,\n",
              "         0.06728444, 0.05560613, 0.03868359, 0.05085114, 0.05349842,\n",
              "         0.05416054, 0.04353723, 0.03987122, 0.04354841, 0.03586248,\n",
              "         0.03390011, 0.04110506, 0.04172093, 0.03959048, 0.04599112],\n",
              "        dtype=float32)),\n",
              " (<__main__.InputExample at 0x7f094c8c0b38>,\n",
              "  array([0.03875712, 0.04331595, 0.05566102, 0.04392928, 0.05001986,\n",
              "         0.04682508, 0.04820842, 0.08334613, 0.07532948, 0.04183096,\n",
              "         0.04455924, 0.04103661, 0.04673526, 0.05231389, 0.02827668,\n",
              "         0.03947663, 0.03622517, 0.02921879, 0.04672086, 0.04153743,\n",
              "         0.05318308, 0.03527361, 0.03682756, 0.0351457 , 0.02821976,\n",
              "         0.04894403, 0.08527464, 0.07039213, 0.06440699, 0.05018434,\n",
              "         0.04255977, 0.04781649, 0.04959041, 0.04250205, 0.03723609,\n",
              "         0.06711796, 0.05475241, 0.03879914, 0.05071491, 0.05338931,\n",
              "         0.05410716, 0.04365978, 0.03987846, 0.04345885, 0.03554147,\n",
              "         0.03377244, 0.04117095, 0.04168686, 0.03961667, 0.0463177 ],\n",
              "        dtype=float32)),\n",
              " (<__main__.InputExample at 0x7f094c8c0b70>,\n",
              "  array([0.03876781, 0.04320288, 0.05603972, 0.0442898 , 0.05006203,\n",
              "         0.0470441 , 0.04800889, 0.08368984, 0.07560176, 0.04175955,\n",
              "         0.04448891, 0.04131424, 0.04668632, 0.05233818, 0.02827871,\n",
              "         0.03925848, 0.03643581, 0.02936369, 0.04686376, 0.0416429 ,\n",
              "         0.05333313, 0.03545633, 0.03649524, 0.03523552, 0.02821869,\n",
              "         0.04892179, 0.08499071, 0.07081145, 0.06457484, 0.05023655,\n",
              "         0.04232788, 0.04791266, 0.04950213, 0.04216424, 0.03718367,\n",
              "         0.06752521, 0.05572176, 0.0387477 , 0.05070937, 0.05348781,\n",
              "         0.05402756, 0.04348767, 0.04001001, 0.04350322, 0.03590873,\n",
              "         0.03411382, 0.04126853, 0.04159957, 0.03953442, 0.04607764],\n",
              "        dtype=float32)),\n",
              " (<__main__.InputExample at 0x7f094c8c0a20>,\n",
              "  array([0.03865603, 0.04316744, 0.05564877, 0.04401499, 0.0502623 ,\n",
              "         0.04704031, 0.04819393, 0.08360726, 0.07563046, 0.04184532,\n",
              "         0.04474926, 0.0410074 , 0.04668051, 0.05217481, 0.02826342,\n",
              "         0.03927246, 0.03654695, 0.02956286, 0.0463728 , 0.04153591,\n",
              "         0.0535548 , 0.03524697, 0.03670439, 0.03529352, 0.02816042,\n",
              "         0.04879704, 0.08576599, 0.07064468, 0.06438434, 0.05043408,\n",
              "         0.04238433, 0.04784852, 0.04958349, 0.04241082, 0.03726399,\n",
              "         0.06717265, 0.05548581, 0.03886178, 0.0508596 , 0.05332881,\n",
              "         0.05405042, 0.0436759 , 0.03986666, 0.04346105, 0.03566295,\n",
              "         0.03396887, 0.04111052, 0.04175428, 0.03950357, 0.04626179],\n",
              "        dtype=float32)),\n",
              " (<__main__.InputExample at 0x7f094c8c0a90>,\n",
              "  array([0.0387831 , 0.04332763, 0.05588871, 0.04392916, 0.05009565,\n",
              "         0.04701382, 0.04796875, 0.08369753, 0.07548788, 0.04171062,\n",
              "         0.04476973, 0.0409492 , 0.04682019, 0.0523105 , 0.02816117,\n",
              "         0.03935063, 0.03651375, 0.02945396, 0.04649162, 0.04142216,\n",
              "         0.05337283, 0.03532091, 0.03666359, 0.03530726, 0.0282658 ,\n",
              "         0.04882532, 0.08549863, 0.07079077, 0.06449467, 0.05049169,\n",
              "         0.04241592, 0.04774269, 0.0495818 , 0.04233906, 0.03734612,\n",
              "         0.06730735, 0.05542484, 0.03891709, 0.05069387, 0.05339494,\n",
              "         0.05428043, 0.0436618 , 0.0399197 , 0.04342815, 0.03573796,\n",
              "         0.03377855, 0.04077363, 0.04173502, 0.0395987 , 0.04623657],\n",
              "        dtype=float32)),\n",
              " (<__main__.InputExample at 0x7f094c8c0dd8>,\n",
              "  array([0.0385412 , 0.0432013 , 0.05622211, 0.04406497, 0.05002189,\n",
              "         0.04726747, 0.04799914, 0.08348629, 0.07581252, 0.0416362 ,\n",
              "         0.04451978, 0.04098016, 0.04688227, 0.05236071, 0.02809966,\n",
              "         0.03917038, 0.0365389 , 0.02942815, 0.04677853, 0.0414615 ,\n",
              "         0.05333486, 0.03506595, 0.03664771, 0.03533038, 0.02814987,\n",
              "         0.04887882, 0.08511382, 0.07044813, 0.06501731, 0.05052686,\n",
              "         0.04236525, 0.04787323, 0.04974774, 0.04211375, 0.03724641,\n",
              "         0.06683207, 0.05548185, 0.03886786, 0.05061907, 0.05333826,\n",
              "         0.05427164, 0.04373118, 0.03986436, 0.04335609, 0.03587914,\n",
              "         0.03380841, 0.04092932, 0.04147449, 0.03959051, 0.04621506],\n",
              "        dtype=float32)),\n",
              " (<__main__.InputExample at 0x7f094c8c0e80>,\n",
              "  array([0.03860679, 0.0433059 , 0.05587855, 0.04399693, 0.05002627,\n",
              "         0.047194  , 0.04806665, 0.08367413, 0.07566336, 0.04188332,\n",
              "         0.04460144, 0.04087555, 0.04685092, 0.05217928, 0.02810186,\n",
              "         0.03920513, 0.03664207, 0.02954802, 0.04648697, 0.04142827,\n",
              "         0.05329755, 0.03511357, 0.03656161, 0.03537112, 0.02815413,\n",
              "         0.04881504, 0.08544785, 0.07076684, 0.06451789, 0.05060777,\n",
              "         0.04242352, 0.04793343, 0.04972756, 0.04233834, 0.03740031,\n",
              "         0.06703803, 0.05559784, 0.03885558, 0.05058131, 0.05335975,\n",
              "         0.05420178, 0.04359198, 0.03986171, 0.04329589, 0.03585845,\n",
              "         0.03381863, 0.04102656, 0.04164177, 0.03956994, 0.04608354],\n",
              "        dtype=float32)),\n",
              " (<__main__.InputExample at 0x7f094c8c0f60>,\n",
              "  array([0.03859565, 0.04321027, 0.05610302, 0.04396057, 0.05010951,\n",
              "         0.04719704, 0.04795673, 0.08365503, 0.07587576, 0.04180023,\n",
              "         0.04470536, 0.04101768, 0.04680419, 0.0525046 , 0.02802458,\n",
              "         0.03923532, 0.03652328, 0.02956146, 0.04650328, 0.04153222,\n",
              "         0.05324286, 0.035267  , 0.03656757, 0.03529641, 0.02825195,\n",
              "         0.04903454, 0.08546913, 0.07065693, 0.06470412, 0.05055547,\n",
              "         0.04215908, 0.04781318, 0.04981497, 0.04208481, 0.03729451,\n",
              "         0.06683755, 0.05566725, 0.03882498, 0.05077884, 0.05335641,\n",
              "         0.05435473, 0.04374692, 0.03983611, 0.04310742, 0.03593138,\n",
              "         0.0338473 , 0.0408183 , 0.04166269, 0.03948948, 0.04610148],\n",
              "        dtype=float32)),\n",
              " (<__main__.InputExample at 0x7f094c8c0fd0>,\n",
              "  array([0.03872839, 0.04326895, 0.05586717, 0.04378861, 0.05015913,\n",
              "         0.047059  , 0.04813209, 0.08358628, 0.07520178, 0.04176512,\n",
              "         0.04470891, 0.04083765, 0.04669985, 0.0521906 , 0.0282793 ,\n",
              "         0.03935465, 0.0363695 , 0.029329  , 0.04656097, 0.04139334,\n",
              "         0.05328387, 0.03520218, 0.03685331, 0.03527117, 0.02822831,\n",
              "         0.04884917, 0.08549616, 0.07029578, 0.06454816, 0.05051255,\n",
              "         0.0426507 , 0.04775429, 0.04963857, 0.04241002, 0.03719741,\n",
              "         0.06702638, 0.0548389 , 0.03888854, 0.05069372, 0.05343354,\n",
              "         0.05413666, 0.04374903, 0.03981793, 0.04347223, 0.03547615,\n",
              "         0.03373542, 0.04103957, 0.04175628, 0.03953761, 0.04637856],\n",
              "        dtype=float32))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bowcedLOOVrI"
      },
      "source": [
        "def gener(predictions):\n",
        "  probabilities = []\n",
        "  for (i, prediction) in enumerate(predictions):\n",
        "        preds = prediction[\"probabilities\"]\n",
        "        for i, value in enumerate(preds):\n",
        "            if value > 0.5:\n",
        "               preds[i] = 1\n",
        "            else:\n",
        "              preds[i] = 0 \n",
        "        tags = test_tag_encoder.inverse_transform(np.array([preds]))\n",
        "        #probabilities.append(preds)\n",
        "  return tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOSce5aIPV9p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "168852a3-1515-4a1e-8bd1-bd768a5ea76c"
      },
      "source": [
        "a = gener(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-205-eba4135a6492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-204-85f632bdb451>\u001b[0m in \u001b[0;36mgener\u001b[0;34m(predictions)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_tag_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#probabilities.append(preds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'tags' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKqaJchBPb3w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "d586a8a9-2f16-4ede-c6c3-8b60c4fad955"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('android',\n",
              "  'asp.net',\n",
              "  'bash',\n",
              "  'c',\n",
              "  'database',\n",
              "  'html',\n",
              "  'jquery',\n",
              "  'json',\n",
              "  'linux',\n",
              "  'multithreading',\n",
              "  'python',\n",
              "  'regex',\n",
              "  'ruby-on-rails',\n",
              "  'ruby-on-rails-3',\n",
              "  'sql')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7n8HbJKQNnT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3774be1f-6bf2-46d5-b54f-a9da1c97aa17"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR6YO1YZMVOL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "7eacb841-038a-44d6-cbb6-d03fc6239f4f"
      },
      "source": [
        "\n",
        "[(sentence, test_tag_encoder.inverse_transform(prediction['probabilities'])) for sentence, prediction in zip(predict_examples, predictions)]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_labels:50;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 50), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 50), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_labels:50;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 50), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 50), dtype=float32)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:**** Trainable Variables ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:**** Trainable Variables ****\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mode: infer probabilities: Tensor(\"loss/Sigmoid:0\", shape=(?, 50), dtype=float32)\n",
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt-140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Pre-processed-Stack-exchange/BERT_OUTPUT/model.ckpt-140\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-b0982a25a47f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tag_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'probabilities'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-120-b0982a25a47f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tag_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'probabilities'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, yt)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m             raise ValueError('Expected indicator for {0} classes, but got {1}'\n\u001b[1;32m   1011\u001b[0m                              .format(len(self.classes_), yt.shape[1]))\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw7mgltJmSlR"
      },
      "source": [
        "def getPrediction(in_sentences):\n",
        "  #labels = [\"Negative\", \"Positive\"]\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h83X5kUYmWFT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "75227214-9622-406a-bef9-a1fadc845153"
      },
      "source": [
        "predictions = getPrediction()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-770bf0871d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pred_sentences' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0CoVLyVm2Rw"
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdEAJCm5m2Ry"
      },
      "source": [
        "##### Thanks for Reading, most of the code is from below examples\n",
        "\n",
        "https://github.com/google-research/bert/blob/master/run_classifier.py\n",
        "\n",
        "https://github.com/yajian/bert/blob/master/run_multilabels_classifier.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuD_VVOjm2Ry"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}